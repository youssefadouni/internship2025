remote sensing
Review
Change Detection Based on Artificial Intelligence:
State-of-the-Art and Challenges
WenzhongShi1,MinZhang1,2,* ,RuiZhang1,3,ShanxiongChen1,2 andZhaoZhan1,2
1 DepartmentofLandSurveyingandGeo-Informatics,TheHongKongPolytechnicUniversity,HungHom,
HongKong,China;lswzshi@polyu.edu.hk(W.S.);rzhang@cumt.edu.cn(R.Z.);
shanxiongchen@whu.edu.cn(S.C.);zhanzhao@whu.edu.cn(Z.Z.)
2 SchoolofRemoteSensingandInformationEngineering,WuhanUniversity,Wuhan430079,China
3 SchoolofEnvironmentScienceandSpatialInformatics,ChinaUniversityofMiningandTechnology,
Xuzhou221116,China
* Correspondence: 007zhangmin@whu.edu.cnorlsgi-min.zhang@polyu.edu.hk
(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:1)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)
Received: 13April2020;Accepted: 20May2020;Published: 25May2020
Abstract: Changedetectionbasedonremotesensing(RS)dataisanimportantmethodofdetecting
changesontheEarth’ssurfaceandhasawiderangeofapplicationsinurbanplanning,environmental
monitoring, agriculture investigation, disaster assessment, and map revision. In recent years,
integrated artificial intelligence (AI) technology has become a research focus in developing new
change detection methods. Although some researchers claim that AI-based change detection
approachesoutperformtraditionalchangedetectionapproaches,itisnotimmediatelyobvioushow
andtowhatextentAIcanimprovetheperformanceofchangedetection. Thisreviewfocuseson
thestate-of-the-artmethods,applications,andchallengesofAIforchangedetection. Specifically,
theimplementationprocessofAI-basedchangedetectionisfirstintroduced. Then,thedatafrom
differentsensorsusedforchangedetection,includingopticalRSdata,syntheticapertureradar(SAR)
data,streetviewimages,andcombinedheterogeneousdata,arepresented,andtheavailableopen
datasetsarealsolisted. ThegeneralframeworksofAI-basedchangedetectionmethodsarereviewed
and analyzed systematically, and the unsupervised schemes used in AI-based change detection
arefurtheranalyzed. Subsequently,thecommonlyusednetworksinAIforchangedetectionare
described. Fromapracticalpointofview,theapplicationdomainsofAI-basedchangedetection
methodsareclassifiedbasedontheirapplicability. Finally,themajorchallengesandprospectsofAI
forchangedetectionarediscussedanddelineated,including(a)heterogeneousbigdataprocessing,
(b)unsupervisedAI,and(c)thereliabilityofAI.Thisreviewwillbebeneficialforresearchersin
understandingthisfield.
Keywords: artificialintelligence;changedetection;remotesensing;deeplearning;neuralnetwork;
unsupervisedlearning;SAR;hyperspectral;multispectral;streetview
1. Introduction
Changedetectionistheprocessofidentifyingdifferencesinthestateofanobjectorphenomenon
byobservingitatdifferenttimes[1]. Itisoneofthemajorproblemsinearthobservationandhasbeen
extensivelyresearchedinrecentdecades. Multi-temporalRSdata,suchassatelliteimageryandaerial
imagery,canprovideabundantinformationtoidentifylanduseandlandcover(LULC)differences
inaspecificareaacrossaperiodoftime. Thisisverycrucialinvariousapplications,suchasurban
planning,environmentalmonitoring,agricultureinvestigation,disasterassessment,andmaprevision.
WiththeongoingdevelopmentofEarthobservationtechniques,hugeamountsofRSdatawith
a high spectral–spatial–temporal resolution are now available, which brings new requirements of
RemoteSens.2020,12,1688;doi:10.3390/rs12101688 www.mdpi.com/journal/remotesensing
RemoteSens.2020,12,1688 2of35
Remote Sens. 2020, 12, x FOR PEER REVIEW 2 of 36
change detection techniques and greatly promotes their development. To address the problems
change detection techniques and greatly promotes their development. To address the problems
brobruoguhgthat baobuotutb ybyfi fnineerrs pspaatitaiall aanndd ssppeeccttrraall rreessoolluuttiioonn imimaaggees sdduurirnign gthteh echcahnagneg deedteectteioctni opnropcreoscs,e ss,
mamnayncyh cahnagneged edteetcetcitoionna apppprrooaacchheess aarree pprrooppoosseedd.. HHeerree, ,ththeeyy araer ebrboraodaldyl ydidviivdiedde idntion ttowtow coatceagtoergieosr:i es:
tratdraidtiiotinoanlaal nanddA AII--bbaasseedd.. FFigiguurere 1 1prperseesnetns ttsheth geengeernael rfalolwfl oowf troafdittriaodniatli ocnhaanlgceh adnetgeectdioent eacntido nAIa-nd
AIb-basaesded chcahnagneg deedteecteticotnio. n.
FiFgiugurere1 1..G Geenneerraall sscchheemmaattiicc ddiiaaggrraamm ooff cchhaannggee ddeteetcetcitoino.n .
Existing change detection reviews have focused mainly on the design of change detection
Existing change detection reviews have focused mainly on the design of change detection
tecthenchiqnuiqeuseisn inm mulutil-tti-etmemppoorarallh hyyppeerrssppeeccttrraall iimmaaggeess ((HHSSIIss)) aanndd hhigighh-s-pspataitaila-lr-erseosloultuiotino inmiamgaegs e[1s-[41]–. 4].
ThTehtee cthecnhiqnuiqeusesth tehyeyr erveiveiweweedda arerem maaiinnllyy ttrraaddiittiioonnaall cchhaannggee ddeetetecctitoionn apapprporaocahcehse, sw, hwichhic chanca bne be
gengeenraelrlayllsyu smummmaraizriezdedin itnotot htheef ofolllolowwiningg ggrroouuppss::
 Visual analysis: the change map is obtained by manual interpretation, which can provide highly
• Visualanalysis: thechangemapisobtainedbymanualinterpretation,whichcanprovidehighly
reliable results based on expert knowledge but is time-consuming and labor-intensive;
reliableresultsbasedonexpertknowledgebutistime-consumingandlabor-intensive;
 aAlgebra-based methods: the change map is obtained by performing algebraic operation or
• aAlgebra-based methods: the change map is obtained by performing algebraic operation
transformation on multi-temporal data, such as image differencing, image regression, image
orrattrioainnsgf,o arnmda ctihoanngoen vemctuorl tai-ntaelmyspiso r(CalVAda);ta, such as image differencing, image regression,
 imTarganesrfaotriominatgio,ann: ddactha arnedguecvtieocnto mreatnhaoldyss,i ssu(CchV aAs) p;rinciple component analysis (PCA), Tasseled
• TrCaanps f(oKrTm),a mtiounlt:ivdaartiaatree adlutecrtaiotinonm deethteocdtiso,ns u(MchAaDs)p, rGinracmipmle–cSocmhmpoidnte (nGtSa)n, aalnyds iCsh(Pi-CSqAu)a,rTea, sasreeled
Cuapsed(K toT )s,umppurletsisv acorirarteelaateldte irnaftoiormnadtieotne catniodn hi(gMhAligDh)t, vGarriaamncme i–nS mchumltiid-ttem(GpSo)r,ala dnadtaC; hi-Square,
 arCeluassseidfitcoatsiuopn-pbraessesdc omrerethlaotdesd: icnhfaonrgmesa tairoen idaenndtihfiiegdh bliyg hcotmvapraiarinncge minulmtipulleti c-tleamssipfiocraatilodna mtaa;ps
• C(lia.ses.,i fipcoastt-icolnas-bsiafisceadtiomne cthomodpsa:ricshoann),g oesr aurseinidg ean ttirfiaeindedby clcaosmsifpiearr itnog dmiruelcttilpyl eclcalsassisfyifi dcaattiao nfrommaps
multiple periods (i.e., multidate classification or direct classification);
(i.e.,post-classificationcomparison),orusingatrainedclassifiertodirectlyclassifydatafrom
 Advanced models: advanced models, such as the Li-Strahler reflectance model, the spectral
multipleperiods(i.e.,multidateclassificationordirectclassification);
mixture model, and the biophysical parameter method, are used to convert the spectral
• Advanced models: advanced models, such as the Li-Strahler reflectance model, the spectral
reflectance values of multi-period data into physically based parameters or fractions to perform
mixture model, and the biophysical parameter method, are used to convert the spectral
change analysis, and this is more intuitive and has physical meaning, but it is complicated and
reflectancevaluesofmulti-perioddataintophysicallybasedparametersorfractionstoperform
time-consuming;
change analysis, and this is more intuitive and has physical meaning, but it is complicated
 Others: hybrid approaches and others, such as knowledge-based, spatial-statistics-based, and
andtime-consuming;
integrated GIS and RS methods, are used.
• OtAhcecros:rdihnygb troid thaep pdreoteaccthioens uannidt, oththeseer sm, estuhcohdsa scaknn aolwsol ebdeg ecl-absassifeided, sbpaasetida lo-snt aptiisxteilc-sle-bvaesl,ed,
feaatnudrei-nletveeglr, aotebdjecGt-IlSevaenld, aRnSdm thetrheeo-ddsi,maernesuiosneds .(3D) object-level, and have been systematically
reviewed in the literature [5–7]. Due to the rapid development of computer technology, the research
According to the detection unit, these methods can also be classified based on pixel-level,
of traditional change detection approaches has turned to integrating AI techniques. In both
feature-level, object-level, and three-dimensions (3D) object-level, and have been systematically
traditional change detection flow and AI-based flow, the first step is data acquisition and the aim of
reviewedintheliterature[5–7]. Duetotherapiddevelopmentofcomputertechnology,theresearchof
change detection is to obtain the change detection map for various applications; after preparing the
traditionalchangedetectionapproacheshasturnedtointegratingAItechniques. Inbothtraditional
data, traditional approaches typically consist of two steps, including a homogenization process and
chaan cgheandgeet edcetitoecntiflono wpraoncedssA, wI-bhailsee tdhefl oAwI-,btahseedfi arsptpsrtoeapchiessd gaetnaearaclqlyu irseitqiuoinrea annd etxhteraa tirmainoifncgh saent ge
RemoteSens.2020,12,1688 3of35
detection is to obtain the change detection map for various applications; after preparing the data,
traditionalapproachestypicallyconsistoftwosteps,includingahomogenizationprocessandachange
detectionprocess,whiletheAI-basedapproachesgenerallyrequireanextratrainingsetgeneration
processandanAImodeltrainingprocessforchangedetection. Obviously,thekeycomponentsof
AI-basedapproachesaretheAItechniques.
AI techniques, also called machine intelligence, can provide a better performance in various
data-processing tasks. It can be defined as a system’s ability to correctly interpret external data,
tolearnfromsuchdata,andtousethoselearningstoachievespecificgoalsandtasksthroughflexible
adaptation[8]. AItechniquesinthispaperfocusontherecentemergenceofdeeplearningmethods,
newnetworkstructures,andintelligentmachinelearningmethods,whichareinspiredbybiological
systems. Traditionalmachinelearningmethods,suchassupportvectormachinesanddecisiontrees,
havenotbeenconsideredinthisreviewduetotheirrelativelylowintelligenceandexistingreviews[7].
ManynewapproachesintegratingAItechniqueshavebeendevelopedtoimprovetheaccuracy
andautomationofchangedetection. AwidebodyofRSresearchhassuggestedthatAI-basedchange
detectionapproachesaresuperiortothetraditionalintermsoffeatureextraction[9,10]. Duetothe
powerfulmodelingandlearningcapabilities,AItechniquescanmodeltherelationshipbetweenthe
imageobjectanditsreal-worldgeographicalfeatureascloselyaspossible,whichenablesthedetection
ofmorerealchangeinformation. Generally,theyutilizespatial-contextinformationinmulti-temporal
datatolearnhierarchicalfeaturerepresentations,andthesehigh-levelfeaturerepresentationsaremore
effectiveandrobustinchangedetectiontasks.
MostexistingstudiesreviewingAIhaveeitherbeengeneralreviewsconcerningthedevelopment
of the AI algorithm [11] or detailed RS application reviews for a specific hot-field [12]. In [13],
theauthorsfocusedonthetheories,tools,andchallengesofdeeplearninginRScommunity. Inother
words,thesereviewarticlesarebasedonthetheoryandapplicationofAItechniquesinRS.Inthe
field of RS data change detection, there is still a lack of a thorough review of AI methods applied
tomulti-sourcedata. ThispaperprovidesadeepreviewoftheapplicationofAItechnologiesinRS
changedetectionprocessing. Itfocusesonthestate-of-the-artmethods,applications,andchallengesof
AIforchangedetectioninmulti-temporaldata. Themaincontributionsofthispaperareasfollows:
1. The implementation process of AI-based change detection is introduced, and we summarize
commonimplementationstrategiesthatcanhelpbeginnersunderstandthisresearchfield;
2. WepresentthedatafromdifferentsensorsusedforAI-basedchangedetectionindetail,mainly
including optical RS data, SAR data, street-view images, and combined heterogeneous data.
Morepractically, we list the available open datasets with annotations, which can be used as
benchmarksfortrainingandevaluatingAImodelsinfuturechangedetectionstudies;
3. BysystematicallyreviewingandanalyzingtheprocessofAI-basedchangedetectionmethods,
wesummarizetheirgeneralframeworksinapracticalway,whichcanhelptodesignchange
detectionapproachesinthefuture. Furthermore,theunsupervisedschemesusedinAI-based
change detection are analyzed to help address the problem of lack of training samples in
practicalapplications;
4. WedescribethecommonlyusednetworksinAIforchangedetection. Analyzingtheirapplicability
ishelpfulfortheselectionofAImodelsinpracticalapplications;
5. WeprovidetheapplicationofAI-basedchangedetectioninvariousfields,andsubdivideitinto
differentdatatypes,whichhelpsthoseinterestedintheseareastofindrelevantAI-basedchange
detectionapproaches;
6. WedelineateanddiscussthechallengesandprospectsofAIforchangedetectionfromthree
majordirections,i.e.,heterogeneousbigdataprocessing,unsupervisedAI,andthereliabilityof
AI,providingausefulreferenceforfutureresearch.
The rest of the paper is organized as follows. We introduce the implementation process of
AI-basedchangedetectioninSection2;andwelistdatasourcesusedforchangedetectioninSection3;
RemoteSens.2020,12,1688 4of35
Thereview of general frameworks and commonly used networks in AI for change detection are
presentedinSections4and5,respectively;inSection6,wesummarizethevariousapplicationsofthe
methods;afterdiscussingthechallengesandopportunitiesofAI-basedchangedetectioninSection7,
wedrawconclusionsofthisreviewinSection8.
2. ImplementationProcessofAI-BasedChangeDetection
Figure 1 illustrates the general flow of AI-based change detection. The key is to obtain a
high-performancetrainedAImodel. Indetail,aspresentedinFigure2,theimplementationprocessof
AI-basedchangedetectionincludesthefollowingfourmainsteps:
1. Homogenization: Due to differences in illumination and atmospheric conditions, seasons,
andsensorattitudesatthetimeofacquisition,multi-perioddatausuallyneedtobehomogenized
before change detection. Geometric and radiometric correction are two commonly used
methods [14,15]. The former aims to geometrically align two or more given pieces of data,
which can be achieved through registration or co-registration. Given two period data, only
whentheyareoverlaidcanthecomparisonbetweencorrespondingpositionsbemeaningful[16].
Thelatteraimstoeliminateradianceorreflectancedifferencescausedbythedigitalizationprocess
ofsensorsandatmosphericattenuationdistortioncausedbyabsorptionandscatteringinthe
atmosphere[4],whichhelpstoreducefalsealarmscausedbytheseradiationerrorsinchange
detection. Forheterogeneousdata,aspecialAImodelstructurecanbedesignedforfeaturespace
transformationtoachievechangedetection(seeSection4.1.2);
2. Trainingsetgeneration: TodeveloptheAImodel,alarge,high-qualitytrainingsetisrequired
thatcanhelpalgorithmstounderstandthatcertainpatternsorseriesofoutcomescomewitha
givenquestion. Multi-perioddataarelabeledorannotatedusingcertaintechniques(e.g.,manual
annotation[17],pre-classification[18],useofthematicdata[19])tomakeiteasyfortheAImodel
tolearnthecharacteristicsofthechangedobjects. Figure2presentsanannotatedexamplefor
buildingchangedetection,whichiscomposedoftwo-periodRSimagesandacorresponding
groundtruthlabeledwithbuildingchangesatthepixellevel. Basedonthegroundtruth,i.e.,prior
knowledge,theAImodelcanbetrainedinasupervisedmanner. Toalleviatetheproblemoflack
oftrainingdata,dataaugmentation,whichiswidelyused,isagoodstrategy,suchashorizontal
orverticalflip,rotation,changeinscale,crop,translation,oraddingnoise,whichcansignificantly
increasethediversityofdataavailablefortrainingmodels,withoutactuallycollectingnewdata;
3. Modeltraining: Afterthetrainingsetisgenerated,itcanusuallybedividedintotwodatasets
accordingtothenumberofsamplesorthegeographicarea: atrainingsetforAImodeltraining
andatestsetforaccuracyevaluationduringthetrainingprocess[20]. Thetrainingandtesting
processes are performed alternately and iteratively. During the training process, the model
is optimized according to a learning criterion, which can be a loss function in deep learning
(e.g., softmax loss [21], contrastive loss [22], Euclidean loss [23], or cross-entropy loss [24]).
Bymonitoringthetrainingprocessandtestaccuracy,theconvergencestateoftheAImodelcan
beobtained,whichcanhelpinadjustingitshyperparameters(suchasthelearningrate),andalso
injudgingwhetherthemodelperformancehasreachedthebest(i.e.,termination)condition;
4. Modelserving: BydeployingatrainedAImodel,changemapscanbegeneratedmoreintelligently
andautomaticallyforpracticalapplications. Moreover,thiscanhelpvalidatethegeneralization
abilityandrobustnessofthemodel,whichisanimportantaspectofevaluatingthepracticalityof
theAI-basedchangedetectiontechnique.
RemoteSens.2020,12,1688 5of35
Remote Sens. 2020, 12, x FOR PEER REVIEW 5 of 36
FigFuigruer2e. 2I.m Implpelmemenentatatitoionnp prroocceessss ooff AAII--bbaasseedd cchhaannggee ddeetteecctitoionn (b(blalcakc kararrorwows isnidnidcaictea tweowrkofrlkoflwo awnda nd
redreadr raorrwowin idnidcaictaetsesa nane xeaxmampplele).).
ThTehaeb aobvoevset esptespps rporvoivdiedae gae gneenrearlailm implpemlemenetnattaiotinonp rporcoecsessso foAf AI-Ib-absaesdedc hcahnanggeed deteetcetcitoionn,,b buuttt he
strtuhcet usrtreuocftuthree AofI tmheo dAeIl imsdodiveel risse dainvdernsee eadnsdt onbeeedws etlol dbees iwgneelld daecsciogrndeidn gactcoodrdiffinegre ntot adpifpfelirceantti on
sitaupaptiloicnastiaonnd sitthueattiroanins ianngdd thatea t,rwaihniinchg wdaitlla,b wehinicthro wduilcl ebde iinntrSoedctuicoends i4n aSnedcti5o.nIst 4is awndo r5t.h Itm ise wntoiortnhi ng
thamteenxtiisotniningg mthaattu erxeisftrianmg emwaoturrkes fsruamchewasorTkesn ssuocrhF laosw Te[n25so],rFKleorwa s[2[52]6, ]K, ePryatso [r2c6h], [P27y]t,oracnhd [2C7a],ff aen[d2 8],
heClpafrfees [e2a8r]c, hheerlsp mreoserearecahseirlsy mreoarlei zeeastihlye rdeeasliizgen ,thtera dinesiniggn,, atnradindinegp,l oanydm deneptloofymAeInmt oodf eAlIs ,maonddeltsh, eir
and their development documents provide detailed introductions.
developmentdocumentsprovidedetailedintroductions.
3.3D. aDtaatSa oSuorucrecsesf ofrorC ChhaannggeeD Deetteeccttiioonn
With the development of data acquisition platforms such as satellites, drones, and ground
Withthedevelopmentofdataacquisitionplatformssuchassatellites,drones,andgroundsurvey
survey vehicles, the massive multi-source RS data that they produce bring forth new application
vehicles,themassivemulti-sourceRSdatathattheyproducebringforthnewapplicationrequirements
requirements for land change monitoring. In particular, multi-sensor high-spatial and high-temporal-
forlandchangemonitoring. Inparticular,multi-sensorhigh-spatialandhigh-temporal-resolution
resolution data require more automated and robust change detection methods to reduce the cost of
data require more automated and robust change detection methods to reduce the cost of manual
manual interpretation. By summarizing the data types used for change detection, we can deeply
interpretation. Bysummarizingthedatatypesusedforchangedetection,wecandeeplyanalyzethe
analyze the applicability of existing change detection methods to the data. In this paper, the types of
applicabilityofexistingchangedetectionmethodstothedata. Inthispaper,thetypesofdatausedfor
data used for change detection are divided into optical RS images, SAR images, and street view
changedetectionaredividedintoopticalRSimages,SARimages,andstreetviewimages. Itshould
images. It should be noted that street view images are usually not used as RS data but as auxiliary
benotedthatstreetviewimagesareusuallynotusedasRSdatabutasauxiliarydata[29–31],soit
data [29–31], so it is not common in the RS community. Still, there are overlapping ideas for change
isnotcommonintheRScommunity. Still,thereareoverlappingideasforchangedetection. Inthis
detection. In this paper, street view images are treated as a kind of RS data in a broad sense and
paper, streetviewimagesaretreatedasakindofRSdatainabroadsenseandreviewed, because
reviewed, because they can provide street-level observation data. Moreover, the methods combining
thehyetcearnogpernoevoiudse dstarteae fto-lre vchealnogbes edrevtaetcitoionnd aartea .suMmomreaorvizeer,dt haendm aenthaloydzsedco. mExbaimnipnlgesh oeft edrioffgeerneenot udsatdaa ta
forsocuhracnegs eardee tsehcotwionn ianr eFisguumrem 3a. rOizpetdicaaln RdSa nanadly zSeAdR. iEmxaagmesp laerse ogfadthiff ereerde nwtidtha tpaassosuivrec easnadr eacsthivoew n
insFeingsuorres,3 r.esOppectitcivaellRy,S caonvedriSnAg Rdiifmfearegnets ealercetrgoamthaegrneedtiwc sipthecptraasls riavnegaens.d Oatchteivr edastean ssoourrsc,erse,s spueccht iavse ly,
covdeigriitnagl edleiff vaetrieonnt meloedcetrlso m(DaEgMnest)i, cgesopgercatrpahlicr ainnfgoersm.atOiotnh esrysdteamta (sGoIuSr)c desa,tas,u acnhd apsodinitg citlaoludel edvaatati, on
mocdanel psr(oDvEidMes v),aglueaobglrea psuhpicpilnemfoernmtaartiyo anttsryibstuetmes.( GOIvSe)rdhaetaad, arenmdoptoei nsetncslionugd cdoallteac,tsc ainnfporromvaitdioenv aolvuearb le
sulpaprgleem speanttiaarl yaraetatrsi, bbuutte sit.s Otimveer hreesaodlurteiomn oitse resleantisvinelgy cloowlle. cSttsreinetf ovrimewa tiimonagoevs ecranla rpgreovsipdaet niaelaarlrye as,
burteiatls-ttiimmee irnefsoorlmutaitoionni sarte slatrteivete-llyevleolw. .FoSrt rdeeettavilieedw dimesacrgiepsticoanns porf oovpidtiecanl eRaSr lyimreagale-st,i mSAeRin ifmoramgeast,i on
atssttrreeeet tv-lieewve ilm. aFgoers, danetda ciloemdbdineesdcr hipetteiorongseonfeooupst dicaatla,R pSleaimsea rgeefesr, tSoA SRectiimona 3g.e1s. ,Ins tardedetitivoine,w Seicmtioang es,
an3d.2c olimstsb ienxeidstihnegt eorpoegne ndeatoaussetds afotar, cphlaenagsee rdeefteercttioonS etacstikosn th3a.1t .cIann abde deimtiopnlo,ySeedc taiso nbe3n.2chlmistasrkesx ifsotri ng
future research.
opendatasetsforchangedetectiontasksthatcanbeemployedasbenchmarksforfutureresearch.
RemoteSens.2020,12,1688 6of35
Remote Sens. 2020, 12, x FOR PEER REVIEW 6 of 36
(a) (b) (c)
(d) (e) (f)
FFiigguurree 33.. EExxaammpplleess ooff ddiiffffeerreenntt ddaattaa ssoouurrcceess ffoorr cchhaannggee ddeetteeccttiioonn:: ((aa)) OOppttiiccaall RRSS iimmaaggee ((oobbttaaiinneedd bbyy
QQuuiicckkbbiirrdd));; (b(b))S ASARRim imagaeg(eo b(otabitnaeindebdy bthye tAhed vAadnvceadncLeadn dLaOnbds eOrvbisnegrvSiantegl lSitaete(AlliLteO S(A)PLhOaSs)e dPhAarsready
tAyrpreayL -tbyapned LS-ybnatnhde tiScyAnptheerttiucr eARpaedrtaurr(eP ARaLdSaArR ()P);A(cL)SdAigRi)t)a; l(ecl)e vdaigtiiotnal meloedvealti(oDnE Mm)o;d(del) g(DeoEgMra)p; h(dic)
ignefoogrrmapathioicn isnyfostremmat(iGonIS s)ydsatetam( f(rGomIS)O dpaetna S(tfrreoemtM Oappe[n3S2t]r)e;e(etM)Paopi n[3t2cl]o);u (de)d Paotain(tf rcolmouIdn tdearntaa t(ifornomal
SInotceierntyatfioornPahl oStoocgireatym fmore tPryhoatnodgRraemmmoteetrSye nasnindg R(eISmPoRtSe) Sbeennscihnmg a(rISkPsR[3S3)] )b;e(nf)cShtmreaertkvsi e[w33i]m); a(gf)e S(ftrroemet
Cviietyws ciampaegsed (afrtaosmet sC[i3ty4s]c).apes datasets [34]).
3.1. DataUsedforChangeDetection
3.1. Data Used for Change Detection
3.1.1. OpticalRSImages
3.1.1. Optical RS Images
OpticalRSimagescanbedividedintohyperspectral,multispectral,andpanchromaticimages
Optical RS images can be divided into hyperspectral, multispectral, and panchromatic images
accordingtothenumberofbands. HSIsarevolumetricimagecubesthatconsistofhundredsofspectral
according to the number of bands. HSIs are volumetric image cubes that consist of hundreds of
bands. Theyhavenarrowbandsoverawideportionoftheelectromagneticspectrum;thebandrange
spectral bands. They have narrow bands over a wide portion of the electromagnetic spectrum; the
isgenerallylessthan10nm. Multispectralimagestypicallycontainmultiplebandsbutfewerthan
band range is generally less than 10 nm. Multispectral images typically contain multiple bands but
15bands. Thespectralresolutionofmultispectralimagesisintherangeof0.1timesthewavelengths.
fewer than 15 bands. The spectral resolution of multispectral images is in the range of 0.1 times the
Panchromaticimageshaveasinglebandthatisformedbyusingthetotallightenergyinthevisible
wavelengths. Panchromatic images have a single band that is formed by using the total light energy
spectrum(insteadofpartitioningitintodifferentspectra). Aside-by-sideexampleofhyperspectral,
in the visible spectrum (instead of partitioning it into different spectra). A side-by-side example of
multispectral, and panchromatic images is shown in Figure 4. HSIs are gathered by the AVIRIS
hyperspectral, multispectral, and panchromatic images is shown in Figure 4. HSIs are gathered by
sensor[35];multispectralandpanchromaticimagesaretakenfromtheQuickbirdsatellite. Thesecond
the AVIRIS sensor [35]; multispectral and panchromatic images are taken from the Quickbird satellite.
rowofFigure4showsthespectralintensityofaselectedimagepixelandthespectralresolutionof
The second row of Figure 4 shows the spectral intensity of a selected image pixel and the spectral
thethreetypesofimages. Therefore,imageswithdifferentnumberofbands,reflectingthespectral
resolution of the three types of images. Therefore, images with different number of bands, reflecting
resolution,requiredifferentmethodsforchangedetection.
the spectral resolution, require different methods for change detection.
HSIs have hundreds or even thousands of continuous and narrow bands, which can provide
abundant spectral and spatial information. Multi-temporal HSIs are of great significance in
distinguishingthesubtlechangesingroundobjectsthroughtheirhigh-dimensionalfeatureinformation.
The detailed information on spectral changes presents promising change detection performance.
However,itincreasestheredundancyofthedataandmakesitdifficulttointerpret. Moreover,dueto
thegenerallylowspatialresolutionofHSIs,thetexturesaroundthepixelsarevague,andmixedpixels
occupyalargeproportion. ChangedetectionmethodsforHSIsmustaddresstheproblemsofhigh
RemoteSens.2020,12,1688 7of35
dimensionality,mixedpixels,highcomputationalcost,andalimitedtrainingdataset. EffectiveAI
algorithmscanbeemployedtosolvetheseproblemsandhavebeenprovedtoachievesatisfactory
performance[36–39].
Multispectralimagescanbeacquiredeconomicallyandstably,withspatialresolutionranging
fromlowtohigh. Theycanproviderichcolors,textures,andotherproperties. Imageswithhighspatial
resolutionorveryhighspatialresolution(10to100cm/pixel)canalsoreflectthestructureinformation
of the ground objects [40]. Consequently, they are widely used for change detection. Specifically,
themostcommonlyusedtypesofmultispectralimagesforAI-basedchangedetectionmethodsare
derivedfromtheLandsatseriesofsatellites[41–65]andtheSentinelseriesofsatellites[66,67],dueto
their low acquisition cost and high time and space coverage. In addition, other satellites, such as
Quickbird[68–74],SPOTseries[75–78],Gaofenseries[14,79,80],Worldviewseries[81–85],provide
highandveryhighspatialresolutionimages,andvariousaircraftsprovideveryhighspatialresolution
aerialimages[20,86–94],allowingthechangedetectionresultstoretainmoredetailsofthechanges.
Remote Sens. 2020, 12, x FOR PEER REVIEW 7 of 36
FigFuigreur4e. E4x. amExpalmespolfesh yopfe rhspyepcetrrsapl,emctruallt,i spmeuclttriaslp,eacntrdalp, anacnhdr opmaantcihcriommaagteisc, wimhaegreest,h ehwyhpeerres ptehcetr al
imhagypeeirssfpreocmtraIln dimianagPei nies s;frmomul tiIsnpdeicatnra lPainneds;p amnuchltrisopmecattriacl imanadg espaanrechfrroommaQtiuc icimkbaigrdes. are from
Quickbird.
Apanchromaticimagehasonlyoneband(i.e.,blackandwhiteband),andusuallycontainsa
coupleHofSIhsu hnadvree dhunnadnroedmse oter rebvaenn dthwoiudstahn.dTs hoef bcoanntdinwuiodutsh aennda bnlaersroitwt obahnodlds, awhhiigchh csaignn parlo—vindoei se
rataiob,umndaaknint gsptheectpraaln cahnrdo mspaattiicadl aitnafoarvmaailtaiobnle. aMtaulhtii-gtehmapnodravle rHyShIsig harsep aotfi aglrreeasto lsuitginoinfi.cTanhceer eifno re,
pandcishtrinomguaitsihcinimg agthees asruebutlseu aclhlyanfugseesd iwn itghromuunldti sopbejcetcrtasl itmhraoguegshto tohbetiar inhrigichh-edrimspeencstiroanlailn ffoeramtuarteio n
andinsfopramtiaatlioinnf.o Trmhea tdioentaifloerdc hinafnogrmeadteiotenc toionn swpeicthtrahli gchhaanngdesv eprryesheingths sppraotmiailsirnegso cluhatinogne. Idnetaedcdtioitnio n,
thepyercfaonrmbeanucsee. dHdoiwreecvtleyr,f iotr inchcraenagseesd tehtee crteidonun[d95a]n.cy of the data and makes it difficult to interpret.
MoOrepotivcearl, RdSuei mtoa gthees agreenewraidlleyl ylouwt ilsipzaetdiafl orrescohlauntigoen doef teHcStiIos,n thaes tthexetyurperso varidouenadb uthned panixteslsp eacretr al
andvasgpuaet,i aanldin mfoixremda ptiioxenl.s oHccouwpeyv ae lra,rogpe tpicraolpsoertniosonr. sCrhealnygue pdoetnectthioens mune’tshoildlus mforin HaStiIos nmaunstd atdhdereussse d
wa
t
v
h
e
e
l e
p
n
ro
g
b
th
le
i
m
s
s
c l
o
o
f
s e
hi
t
g
o
h
v
d
is
im
ib
e
le
ns
li
i
g
on
h
a
t
l
o
it
r
y
1
, m
m
i
m
xe
.
d
T
p
h
i
e
x
r
e
e
ls
f
,
o
h
re
ig
,
h
th
c
e
o
y
m
a
p
re
ut
o
a
f
t
t
i
e
o
n
na
a
lff c
e
o
c
s
t
t
e
,
d
an
b
d
y
a
s o
li
l
m
ar
it
r
e
a
d
d i
t
a
ra
ti
i
o
n
n
in
a
g
n d
dataset. Effective AI algorithms can be employed to solve these problems and have been proved to
clouds. SAR,ontheotherhand,usesawavelengthof1cmto1mandhasitsownilluminationsource.
achieve satisfactory performance [36–39].
Thus,itcanimageatbothdayandnight,inalmostallweatherconditions.
Multispectral images can be acquired economically and stably, with spatial resolution ranging
from low to high. They can provide rich colors, textures, and other properties. Images with high
spatial resolution or very high spatial resolution (10 to 100 cm/pixel) can also reflect the structure
information of the ground objects [40]. Consequently, they are widely used for change detection.
Specifically, the most commonly used types of multispectral images for AI-based change detection
methods are derived from the Landsat series of satellites [41–65] and the Sentinel series of satellites
[66,67], due to their low acquisition cost and high time and space coverage. In addition, other satellites,
such as Quickbird [68–74], SPOT series [75–78], Gaofen series [14,79,80], Worldview series[81–85],
provide high and very high spatial resolution images, and various aircrafts provide very high spatial
resolution aerial images [20,86–94], allowing the change detection results to retain more details of the
changes.
A panchromatic image has only one band (i.e., black and white band), and usually contains a
couple of hundred nanometer bandwidth. The bandwidth enables it to hold a high signal–noise ratio,
making the panchromatic data available at a high and very high spatial resolution. Therefore,
panchromatic images are usually fused with multispectral images to obtain richer spectral
information and spatial information for change detection with high and very high spatial resolution.
In addition, they can be used directly for change detection [95].
RemoteSens.2020,12,1688 8of35
3.1.2. SARImages
SARisatechniquewhichusessignalprocessingtoimprovetheresolutionbeyondthelimitation
ofphysicalantennaaperture[96]. Thesensorismountedonanaircraftorasatellite,andisusedto
makeahigh-resolutionimageoftheearth’ssurface. SARisindependentofatmosphericandsunlight
condition,soithasbecomeavaluablesourceofinformationinchangedetection. Withthedevelopment
ofSARimagingtechnology,multi-platform,multi-band,multi-polarizationSARimagesprovidemore
abundantdatasourcesforchangedetectiontasks. However,SARimagesalwayssufferfromtheeffect
ofspecklenoises,whichresultsinamoredifficultprocessofchangedetectionthanopticalRSimages.
Theirthreekeyproblemsinclude: (1)suppressingspecklenoise;(2)designingachangemetricora
changeindicator;and(3)usingathresholdoraclassifierbasedonachangemetrictogenerateafinal
changemap. ChangedetectionmethodsusingAItechniques,especiallyanautoencoder(AE)[97–107]
andaconvolutionalneuralnetwork(CNN)[108–114],tosuppressspecklenoiseandextractfeatureshas
beenproventobethestateoftheart. Intheoverallprocessandframeworkofmethods,theyaresimilar
tothemethodsbasedonopticalRSimages,andthedetailedframeworkandAImodelintroductionare
analyzedinSections4and5.
3.1.3. StreetViewImages
Unlike optical RS and SAR images, street view images are captured at eye-level instead of
overhead. Theyprovidemoredetailedinformationinrelativelysmallareasandatmoreobservation
angles, whichcanbeusedfordynamicorreal-timechangedetection. Changedetectionbasedon
streetviewimagesfocusesonchangesinthedynamicurbanvisuallandscape,suchastheadditionor
removalofspecificlandmarks,pedestrians,vehicles,andotherroadsidebuildings.
Acriticalchallengeisonhowtoidentifynoisychangescausedbyvariousilluminations,camera
viewpoints, occlusions, and shadows in detecting changes using street view images. These noisy
changesareinterwovenwithsemanticchanges,makingitdifficulttodefineandmeasurethewanted
semanticchangesinstreetviewimages. Thus,usingAIalgorithms,mainlyCNN[115–120],tolearn
deepfeaturesforchangedetection,requiresstreetviewimagesthathavebeenspatiallyregistered.
3.1.4. CombiningHeterogeneousData
Accordingtowhetherthesourceofmulti-perioddataisthesame,thechangedetectionmethods
canbedividedintohomogeneousdatachangedetectionandheterogeneousdatachangedetection.
Homogeneousdatacomesfromthesametypeofsensors,andtheyhavethesameproperties,spectral
distribution, and feature space, while heterogeneous data come from different types of sensors,
theyhavedifferentpropertiesandfeaturespaces,sotheycannotbeanalyzeddirectlyfordifference
image. Although change detection using heterogeneous data is more challenging, it has fewer
restrictions on the type of input data and can be used in more situations. Different sensors can
complementeachothertoprovidericherinformationongroundobjects. Forexample,usingopticalRS
imagesandSARimagesforchangedetection,theformercanproviderichtextureinformation,whilethe
lattercanbeacquiredwithoutatmosphericrestrictions. Itcanbeusedforemergencychangedetection
inareaswheredataareinsufficientordisastersoccur. Muchworkonthisissuehasbeenproposed
thatusesAImethodstodetectchangesinSARandopticalRSimages[16,66,121–127]. Inaddition,
GISmaps[128],pointclouddata[91],DEMs[129,130],anddigitalsurfacemodels(DSMs)[131]are
usedincombinationwithopticalRSimagesorSARimagesforchangedetection. Thesedifferentdata
typescansatisfydifferentapplicationrequirementsandareselectedaccordingtotheactualsituation.
3.2. OpenDataSets
Currently,therearesomefreelyavailabledatasetsforchangedetection,whichcanbeusedas
benchmarkdatasetsforAItrainingandaccuracyevaluationinfutureresearch. Detailedinformationis
presentedinTable1.
RemoteSens.2020,12,1688 9of35
Itcanbeseenthattheamountofopendatasetsthatcanbeusedforchangedetectiontasksis
small,andsomeofthemhavesmalldatasizes. Atpresent,thereisstillalackoflargeSARdatasetsthat
canbeusedforAItraining. MostAI-basedchangedetectionmethodsarebasedonseveralSARdata
setsthatcontainlimitedtypesofchanges,e.g.,theBerndataset,theOttawadataset,theYellowRiver
dataset,andtheMexicodataset[24,103],whichcannotmeettheneedsofchangedetectioninareas
withcomplexlandcoverandvariouschangetypes. Moreover,theirlabelsarenotfreelyavailable.
Street-viewdatasetsaregenerallyusedforresearchofAI-basedchangedetectionmethodsincomputer
vision(CV).InCV,changedetectionbasedonpicturesorvideoisalsoahotresearchfield,andthe
basicideaisconsistentwiththatbasedonRSdata. Therefore,inadditiontostreetviewimagedatasets,
severalvideodatasetsinCVcanalsobeusedforresearchonAI-basedchangedetectionmethods,such
asCDNet2012[132]andCDNet2014[133]. Sincetheybelongtotheresearchfieldofvideoanalysis,
thispaperwillnotreviewtheminmoredetail. Thoseinterestedcanreferto[132–134].
Table1. Alistofopendatasetsforchangedetection.
Type DataSet Description
3differenthyperspectralscenesacquiredbyAVIRISor
Hyperspectralchangedetection HYPERIONsensor,with224or242spectralbands,
dataset[135] labeled5typesofchangesrelatedwithcroptransitions
atpixellevel.
2HSIsinJiangsuprovince,China,with198bands,
RiverHSIsdataset[39]
labeledaschangedandunchangedatpixellevel.
291co-registeredpairsofRGBaerialimages,with
pixel-levelchangeandlandcoverannotations,providing
HRSCD[136] hierarchicallevelchangelabels,forexample,level1
labelsincludefiveclasses: noinformation,artificial
surfaces,agriculturalareas,forests,wetlands,andwater.
2-periodaerialimagescontaining12,796buildings,
WHUbuildingdataset[88]
providedalongwithbuildingvectorandrastermaps.
SZTAKIAirchangebenchmark 13aerialimagepairswith1.5mspatialresolution,
[137,138] labeledaschangedandunchangedatpixellevel.
24pairsofmultispectralimagesacquiredbySentinel-2,
OSCD[139]
labeledaschangedandunchangedatpixellevel.
4pairsofmultispectralimageswithdifferentspatial
Changedetectiondataset[140] resolutions,labeledaschangedandunchangedat
OpticalRS pixellevel.
2large-sizeVHRimagesacquiredbyIKONOSsensors,
with4bandsand1mspatialresolution,labeled5types
MtS-WH[141]
ofchanges(i.e.,parking,sparsehouses,residential
region,andvegetationregion)atscenelevel.
16,950pairsofRGBaerialimagesfordetectingwashed
ABCD[92] buildingsbytsunami,labeleddamagedbuildingsat
scenelevel.
Pre-andpost-disastersatelliteimageriesforbuilding
damageassessment,withover850,000building
xBD[142]
polygonsfrom6disastertypes,labeledatpixellevel
with4damagescales.
1000pairsofsyntheticaerialimageswithartificial
AICD[143] changesgeneratedwitharenderingengine,labeledas
changedandunchangedatpixellevel.
24,000syntheticimagesand16,000fragmentsofreal
Databaseofsyntheticandreal
season-varyingRSimagesobtainedbyGoogleEarth,
images[144]
labeledaschangedandunchangedatpixellevel.
Remote Sens. 2020, 12, x FOR PEER REVIEW 10 of 36
24 pairs of multispectral images acquired by
OSCD [139] Sentinel-2, labeled as changed and unchanged
at pixel level.
4 pairs of multispectral images with different
Change detection dataset
spatial resolutions, labeled as changed and
[140]
unchanged at pixel level.
2 large-size VHR images acquired by IKONOS
sensors, with 4 bands and 1 m spatial
MtS-WH [141] resolution, labeled 5 types of changes (i.e.,
parking, sparse houses, residential region, and
vegetation region) at scene level.
16,950 pairs of RGB aerial images for detecting
ABCD [92] washed buildings by tsunami, labeled damaged
buildings at scene level.
Pre- and post-disaster satellite imageries for
RemoteSens.2020,12,1688 10of35
building damage assessment, with over 850,000
xBD [142]
building polygons from 6 disaster types,
Table1. Claobnte.led at pixel level with 4 damage scales.
1000 pairs of synthetic aerial images with
Type DataSet Description
artificial changes generated with a rendering
AICD [143] 1362co-registeredpairsofRGBanddepthimages,
engine, labeled as changed and unchanged at
labeledgroundtruthchange(e.g.,bin,sign,vehicle,
VL-CMU-CD[145] refuse,construction, p tr i a xffiel c l c e o v n e e l , . person/cycle,barrier)
24,000 synthaentdics kimymagaessk saantdp 1ix6e,l0l0e0v eflr.agments of
Database of synthetic and 200repaaln soeraamsoinc-ivmaargyeinpgai rRsSi nim"TaSgUeNs AobMtaI"inanedd "bGyS V"
Streetview PrCeDal 2i0m15ag[1e1s9 []144] subGseot,owglieth Etahretshi,z elaobfe2l2e4d ×as1 0c2h4apnigxeelds, alanbde las
changuendcahnadnguendch aatn pgeixdealt lpevixeell. level.
13Im62a gceos-reeqguiesntceersedof pcaitiyrss torefe RtsGcBap atunrde ddbepytah
vehicle-mountedcameraattwodifferenttimepoints,
Changedetectiondataset[146] i w m it a h g t e h s e , s la iz b e e o le f d 50 g 0 r 0 o × un 25 d 0 0 tr p u i t x h e l c s, h l a a n be g l e e d (e 3 . D g., s c b e i n n e ,
VL-CMU-CD [145] sign, vehicle, refuse, construction, traffic cone,
structurechangesatpixellevel.
person/cycle, barrier) and sky masks at pixel
level.
4. GeneralAI-BasedChangeDetectionFrameworks
200 panoramic image pairs in "TSUNAMI" and
StTreheet viniepwu t of the chaPnCgDe 2d0e1t5e c[1ti1o9n] task is m"GuSltVi-"t esmubpsoerta, lwditaht ath, ew shiziceh ofa 2re24h ×o m10o2g4e pniexoeulss, or
heterogeneousdataintwoormoreperiods. Accordlainbgelt aost hcheadnegeepdf eaantdu ruenecxhtarnacgteiodn aot rpliaxteeln ltevfeeal.t ure
representationlearningprocessofthebi-temporalIdmataag,et hseeqAuIe-nbcaesse dofc chiatyn gsteredeettse ccatipotnurfreadm beyw ao rks
can be summarized into three types: single-streavmeh,icdloeu-mbloeu-snttreeda mca,maenrda amt utwltio- mdiofdfeerlenint tteimgrea ted.
Change detection dataset
Inaddition, we further analyze their unsupervisedpsochinetms, ewiintht hthees esifzrea mofe 5w00o0r k×s 2,5w00h ipchixeisls,a very
[146]
importantandchallengingresearchissueinAI. labeled 3D scene structure changes at pixel
level.
4.1. Single-StreamFramework
They usually only need a core AI model to achieve change detection, so they can be regarded as
Therearetwomaintypesofsingle-streamframeworkstructuresforAI-basedchangedetection,
a single-stream structure. It is worth noting that, in practice, some studies have made improvements
as shown in Figure 5, namely a direct classification structure and a mapping transformation-
based on these structures to meet specific change detection purposes, and a detailed analysis is given
basedstructure.
below.
(a) (b)
Figure5. Schematicdiagramofsingle-streamframeworkstructuresofAI-basedchangedetection:
(a)thedirectclassificationstructure;(b)themappingtransformation-basedstructure.
TheyusuallyonlyneedacoreAImodeltoachievechangedetection,sotheycanberegardedasa
single-streamstructure. Itisworthnotingthat,inpractice,somestudieshavemadeimprovements
based on these structures to meet specific change detection purposes, and a detailed analysis is
givenbelow.
4.1.1. DirectClassificationStructure
Thedirectclassificationmethodsusevariousdataprocessingapproachestofusethetwoormore
periodsofdataintointermediatedata,andasingleAI-basedclassifieristhenusedtoperformfeature
learningandachievetwoormultipleclassificationsofthefusiondata. Thatis,asshowninFigure5a,
thisstructureconvertsthechangedetectiontaskintoaclassificationtask,alsoknownasatwo-channel
structureinsomeoftheliterature[108,147]. Itstwokeyresearchissuesarethechoiceofdatafusion
approachandAI-basedclassifier.
RemoteSens.2020,12,1688 11of35
Toobtainthefusiondatafrommulti-perioddata,thetwomostcommonapproachesareusing
change analysis methods and direct concatenation. Change analysis methods, such as CVA [47],
differencingbylog-ratiooperator[18,148]orchangemeasures[103,149],areabletodirectlyprovide
change intensity information (i.e., the difference data) in multitemporal data, which can highlight
changeinformationandfacilitatechangedetection. Thedirectconcatenationmethodcanretainall
theinformationofthemulti-perioddata,sothechangeinformationisextractedbythesubsequent
classifier. In general, the one-dimensional input data is directly concatenated [24,42,101,150–152],
whilethetwo-dimensionaldataisconcatenatedbychannel[111,112,153,154]. Moreover,thefusionof
originaldataanddifferencedata[21,99]isanothergoodstrategy,whichcankeepalltheinformation
whilehighlightingthedifferenceinformation.
The classifier uses AI techniques to classify the fused data into two types (i.e., changed or
unchanged)ormultipletypes(differenttypesofchanges)[77]. Itsperformanceandrelatedtraining
dataarethekeytofinallyobtainingsatisfactorychangemaps. MoredetailsarereviewedinSection5.
4.1.2. MappingTransformation-BasedStructure
Themappingtransformation-basedframeworkstructureisusuallyusedtodetectchangesin
differentdomainsorheterogeneousdata. ItsmainideaistousetheAImethodtolearnthefeature
mappingtransformation,anduseittoperformfeaturetransformationononekindofdata,asshown
inFigure5b. Thetransformedfeaturescorrespondtothefeaturesofanotherkindofdata. Inshort,
ittransformsdatafromonefeaturespacetoanotherfeaturespace. Finally,thechangemapcanbe
obtained by performing decision analysis on the corresponding features of the two kinds of data.
In[16],amappingneuralnetwork(MNN)isdesignedtolearnthemappingfunctionbetweenthe
multi-spatial-resolutiondata,andthefeaturesimilarityanalysisisthenimplementedtobuildachange
map. ThismethodalsoachieveschangedetectionbetweenSARandopticalimages. In[60],theauthors
useanANNtoachieverelativeradiometricnormalization,andthendetectchangesofthetwo-period
dataunderthesameradiationcondition. Moreover,usingthisideaofmappingtransformation,several
improvedstructureshavebeenproposedfordetectingchangesinheterogeneousdata[121–124]or
differentdomaindata[10].
4.2. Double-StreamFramework
Since the change detection task is usually based on two periods of data, that is, two inputs,
thedouble-streamstructureisverycommonforchangedetectionandcanbesummarizedintothree
types,asshowninFigure6. Theyareasiamesestructure,atransferlearning-basedstructure,anda
post-classificationstructure.
4.2.1. SiameseStructure
AsshowninFigure6a,theSiamesestructuregenerallyconsistsoftwosub-networkswiththesame
structure,i.e.,featureextractors,whichconverttheinputtwo-perioddataintofeaturemaps. Finally,
thechangemapisobtainedbyusingchangeanalysis(i.e.,decisionmaker). Themainadvantageofthis
structureisthatitstwosub-networksaredirectlytrainedatthesametimetolearnthedeepfeaturesof
theinputtwo-perioddata.
According to whether the weights of sub-networks are shared, this can be divided into the
pure-Siamese structure [22,68,94,117,155,156] and the pseudo-Siamese structure [79,109,157,158].
Themaindifferenceisthattheformersub-networkextractsthecommonfeaturesofthetwo-perioddata
bysharingweights. Thelattersub-networkextractsfeaturescorrespondinginputdata,respectively,
resultinginanincreaseinthenumberoftrainableparametersandcomplexity,butalsoinitsflexibility.
Similarly,theauthorsof[159]designedatriplenetworkconsistingofthreesub-networkswithsharing
weightsforchangedetection.
RemoteSens.2020,12,1688 12of35
Remote Sens. 2020, 12, x FOR PEER REVIEW 12 of 36
(a) (b)
(c)
FFiigguurree 66.. SScchheemmaattiicc ddiiaaggrraamm oof fddoouubblel-es-tsrteraemam frfarmameweworokr kstrsutrcutuctruer oef oAfIA-bIa-bseadse cdhacnhgane gdeetdeectteiocnti:o (na:)
(tah)et hSeiaSmiaemsee ssetrsutcrtuucrteu;r (eb;)( bth)eth teratnrasnfesrf-elre-alernarinngin-bga-bsaesde dstrsutrcutuctruer; e(;c()c t)hteh peopsots-ct-lcalsassisfiicfiactaiotino nstsrturcutcuturer.e .
4.2.1A. Sltihamouegshe Sthtrisuscttruurcet ureenablesthefeatureextractortodirectlylearndeepfeaturesbysupervised
training with labeled samples, unsupervised training is more challenging. A common solution is
As shown in Figure 6a, the Siamese structure generally consists of two sub-networks with the
totrainfeatureextractorsindividuallyinanunsupervisedmanner[105–107,160]. Thesepre-trained
same structure, i.e., feature extractors, which convert the input two-period data into feature maps.
featureextractorsprovidethelatentrepresentationoftheoriginaldata(i.e.,featuremaps)forfurther
Finally, the change map is obtained by using change analysis (i.e., decision maker). The main
changedetection. Togeneratechangemaps,theoutputfeaturemapsinthetwoperiodscanbedirectly
advantage of this structure is that its two sub-networks are directly trained at the same time to learn
classifiedbytheconcatenationofchannels[91,155,161]orcanbeusedtoproducedifferencemaps
the deep features of the input two-period data.
using a certain distance metric [9], and then used for further change analysis [162,163]. To retain
According to whether the weights of sub-networks are shared, this can be divided into the pure-
multi-scale change information, feature maps at different depths can be concatenated for change
Siamese structure [22,68,94,117,155,156] and the pseudo-Siamese structure [79,109,157,158]. The main
detection[164–167],andthisworkswell.
difference is that the former sub-network extracts the common features of the two-period data by
sharing weights. The latter sub-network extracts features corresponding input data, respectively,
4.2.2. TransferLearning-BasedStructure
resulting in an increase in the number of trainable parameters and complexity, but also in its
Thetransferlearning-basedstructureisproposedtoalleviatethelackoftrainingsamplesand
flexibility. Similarly, the authors of [159] designed a triple network consisting of three sub-networks
optimizethetrainingprocess. Transferlearningusestraininginonedomaintoenablebetterresultsin
with sharing weights for change detection.
anotherdomainand,specifically,thelowertomidlevelfeatureslearnedintheoriginaldomaincanbe
Although this structure enables the feature extractor to directly learn deep features by
transferredasusefulfeaturesinthenewdomain[13]. Thepre-trainedAImodel,asafeatureextractor,
supervised training with labeled samples, unsupervised training is more challenging. A common
isusedtogeneratefeaturemapsfortwoperiods,andthefeatureextractorsofthetwoperiodscan
solution is to train feature extractors individually in an unsupervised manner [105–107,160]. These
bethesame,asshowninFigure6b. Whetherthepre-trainedmodelcancorrectlyextractthedeep
pre-trained feature extractors provide the latent representation of the original data (i.e., feature maps)
featuremaporlatentfeaturerepresentationoftheinputdatadeterminestheperformanceofthechange
for further change detection. To generate change maps, the output feature maps in the two periods
detectiontask.
can be directly classified by the concatenation of channels [91,155,161] or can be used to produce
Thetransferlearning-basedstructureusuallyhastwotrainingphases,namelythedeepfeature
difference maps using a certain distance metric [9], and then used for further change analysis
learning phase and the fine-tuning phase. In the deep feature learning phase, the AI model is
[162,163]. To retain multi-scale change information, feature maps at different depths can be
usually supervised, pre-trained with sufficient labeled samples in other domain data [67,110,168].
concatenated for change detection [164–167], and this works well.
Thefine-tuning phase is optional and, in this phase, only a small number of labeled samples are
r4e.q2u.2i.r eTdrafnosrffiern Le-etaurnniinngg-[B12a5se,1d6 9S–tr1u7c2t]uorre additionalclassifiertraining[90,140]. Therefore,thechange
mapcanbedirectlyobtainedbythetrainedclassifier. Withoutfine-tuning,finalchangemapscanbe
The transfer learning-based structure is proposed to alleviate the lack of training samples and
obtainedbasedonthetwo-periodfeaturemapsusingchangeanalysis,suchaslowrankanalysis[173],
optimize the training process. Transfer learning uses training in one domain to enable better results
CVA[72],clustering[73,82],andthreshold[119,174]. Thismeansthatnomorelabeledsamplesare
in another domain and, specifically, the lower to midlevel features learned in the original domain can
neededforfurthertraining. Moreover,basedontheideaoftransferlearning,thepre-trainedAImodel
be transferred as useful features in the new domain [13]. The pre-trained AI model, as a feature
can also be used to generate training samples or masks to achieve the unsupervised scheme [78],
extractor, is used to generate feature maps for two periods, and the feature extractors of the two
whichisaverypracticalstrategy.
periods can be the same, as shown in Figure 6b. Whether the pre-trained model can correctly extract
the deep feature map or latent feature representation of the input data determines the performance
of the change detection task.
Remote Sens. 2020, 12, x FOR PEER REVIEW 13 of 36
The transfer learning-based structure usually has two training phases, namely the deep feature
learning phase and the fine-tuning phase. In the deep feature learning phase, the AI model is usually
supervised, pre-trained with sufficient labeled samples in other domain data [67,110,168]. The fine-
tuning phase is optional and, in this phase, only a small number of labeled samples are required for
fine-tuning [125,169–172] or additional classifier training [90,140]. Therefore, the change map can be
directly obtained by the trained classifier. Without fine-tuning, final change maps can be obtained
based on the two-period feature maps using change analysis, such as low rank analysis [173], CVA
[72], clustering [73,82], and threshold [119,174]. This means that no more labeled samples are needed
for further training. Moreover, based on the idea of transfer learning, the pre-trained AI model can
also be used to generate training samples or masks to achieve the unsupervised scheme [78], which
Rise mao vteeSreyn sp.2r0a2c0t,i1c2a,l1 s6t8r8ategy. 13of35
4.2.3. Post-Classification Structure
4.2.3. Post-ClassificationStructure
As shown in Figure 6c, the post-classification structure consists of two classifiers, which can
As shown in Figure 6c, the post-classification structure consists of two classifiers, which can
usually be converted into classification tasks and trained in a joint or independent way. It provides a
usuallybeconvertedintoclassificationtasksandtrainedinajointorindependentway. Itprovidesa
classification map for each period data and the change map with change directions can be obtained
classificationmapforeachperioddataandthechangemapwithchangedirectionscanbeobtained
by comparing classification maps. Nevertheless, the accuracy of the change detection results of these
bycomparingclassificationmaps. Nevertheless,theaccuracyofthechangedetectionresultsofthese
methods depends on the performance of the classifier.
methodsdependsontheperformanceoftheclassifier.
A number of studies [43,44,52,56,61,70,75,76,131,175,176] have proven that AI techniques
Anumberofstudies[43,44,52,56,61,70,75,76,131,175,176]haveproventhatAItechniquesincrease
increase the accuracy of land-cover classification to a notable level and the results can be further used
the accuracy of land-cover classification to a notable level and the results can be further used for
for change detection. By converting the direct geometric or spectral comparison to label changes, the
changedetection. Byconvertingthedirectgeometricorspectralcomparisontolabelchanges, the
post-classification structure can be regarded as a very general and practical structure, and it provides
post-classificationstructurecanberegardedasaverygeneralandpracticalstructure,anditprovidesa
t a y p ty e p c e h a c n h g a e n m ge a tr m ix a . t A rix d . v a A n d ta v g a e n o ta u g sl e y o , u it sl w y, o r i k t s w ro o b r u k s s t ly ro f b o u r s d t a ly ta f a o c r q u d i a re ta d u a n cq d u er ir d ed iff e u r n en d t e a r cq d u if i f s e i r ti e o n n t
c
a
o
cq
n
u
d
i
i
s
ti
i
o
ti
n
o
s
n
( i
c
l
o
lu
n
m
di
i
t
n
io
at
n
io
s
n
(il
c
l
o
u
n
m
d
i
i
n
ti
a
o
t
n
io
,
n
se
c
n
o
s
n
o
d
r
i
a
t
t
i
t
o
it
n
u
,
d
s
e
e
,
n
s
s
e
o
a
r
s
a
o
t
n
t
,
it
e
u
tc
d
.
e
)
,
o
s
r
e
e
a
v
so
e
n
n
,
d
e
i
tffc
e
.)
r e
o
n
r
t
e
s
v
e
e
n
n
s o
d
r
i
s
ff
[
e
4
r
5
e
,
n
50
t
,
s
6
e
2
n
,1
s
3
o
0
rs
].
[45,50,62,130]. Supervised training of the AI-based classifier requires a large number of training
SupervisedtrainingoftheAI-basedclassifierrequiresalargenumberoftrainingsamples,whichcan
samples, which can be generated by existing GIS data representing land cover [128] or thematic maps
begeneratedbyexistingGISdatarepresentinglandcover[128]orthematicmaps[177].
[177].
4.3. Multi-ModelIntegratedStructure
4.3. Multi-Model Integrated Structure
ManyworkshaveintegratedmultipleAImodelstoimprovetheperformanceofchangedetection
Many works have integrated multiple AI models to improve the performance of change
methods. Consideringthelargenumberandcomplexstructure, onlyarepresentativestructureis
detection methods. Considering the large number and complex structure, only a representative
summarized,asshowninFigure7.
structure is summarized, as shown in Figure 7.
FFiigguurree 77.. SScchheemmaattiicc ddiiaaggrraamm ooff mmuullttii--mmooddeell iinntteeggrraatteedd ssttrruuccttuurree ooff AAII--bbaasseedd cchhaannggee ddeetteeccttiioonn..
TThhee mmuullttii--mmooddeell iinntteeggrraatteedd ffrraammeewwoorrkk iiss aa hhyybbrriidd ssttrruuccttuurree,, wwhhiicchh iiss ssiimmiillaarr ttoo tthhee ddoouubbllee
ssttrreeaamm ssttrruuccttuurree,, bbuutt iitt ccoonnttaaiinnss mmoorree ttyyppeess ooff AAII mmooddeellss aanndd ccaann aallssoo bbee ttrraaiinneedd iinn mmuullttiippllee ssttaaggeess..
CChhaannggee ddeetteeccttiioonn iiss aa ssppaattiiootteemmppoorraall aannaallyyssiiss aanndd ccaann bbee aacchhiieevveedd bbyy aaccqquuiirriinngg tthhee ssppaattiiaall––ssppeeccttrraall
ffeeaattuurreess tthhrroouugghh aann AAII--bbaasseedd ffeeaattuurree eexxttrraaccttoorr aass aa ssppeeccttrraall--ssppaattiiaall mmoodduullee,, aanndd tthheenn mmooddeelliinngg
tteemmppoorraall ddeeppeennddeennccyy tthhrroouugghh aann AAII--bbaasseedd ccllaassssiiffiieerr aass aa tteemmppoorraall mmoodduullee [[1144,,3388,,5533,,7744]].. MMoorreeoovveerr,,
tthhiiss hhyybbrriidd ssttrruuccttuurree iiss sskkiillllffuullllyy uusseedd ffoorr uunnssuuppeerrvviisseedd cchhaannggee ddeetteeccttiioonn [[110000]] aanndd oobbjjeecctt--lleevveell
cchhaannggee ddeetteeccttiioonn [[8877]].. TThhiiss mmaakkeess tthhee wwhhoollee cchhaannggee ddeetteeccttiioonn pprroocceessss mmoorree ccoommpplliiccaatteedd wwhhiillee
iimmpprroovviinngg ppeerrffoorrmmaannccee..
4.4. UnsupervisedSchemesinChangeDetectionFrameworks
AI-based change detection frameworks usually include feature extractors or classifiers,
whichrequire supervised and unsupervised training. Since obtaining a large number of labeled
samplesforsupervisedtrainingisusuallytime-consumingandlabor-intensive,manyeffortshave
been made to achieve AI-based change detection in an unsupervised or semi-supervised manner.
AsintroducedinSection4.2.2,transferlearningcanreduceoreveneliminatetheneedfortraining
samples,butthesearenotpureunsupervisedschemes,assamplesfromotherdomainsarerequired.
Inaddition,themostcommonlyusedunsupervisedschemeistousethechangeanalysismethodand
Remote Sens. 2020, 12, x FOR PEER REVIEW 14 of 36
4.4. Unsupervised Schemes in Change Detection Frameworks
AI-based change detection frameworks usually include feature extractors or classifiers, which
require supervised and unsupervised training. Since obtaining a large number of labeled samples for
supervised training is usually time-consuming and labor-intensive, many efforts have been made to
achieve AI-based change detection in an unsupervised or semi-supervised manner. As introduced in
RSeemctoitoeSne n4s..22.022,0 t,r1a2n,1s6f8e8r learning can reduce or even eliminate the need for training samples, but1 t4hoefs3e5
are not pure unsupervised schemes, as samples from other domains are required. In addition, the
m sa o m st p l c e o s m el m ec o t n io ly n s u t s r e a d te g u y ns to up se er le v c i t se a d b s s o c l h u e te m c e h a is n g to e d u o se r/ a t n h d e u ch n a ch n a g n e g a e n d a a ly s s t i r s a i m ni e n th g o s d a m an p d le s sa fo m r p A le I
selection strategy to select absolute changed or/and unchanged as training samples for AI models. Its
models. ItsflowchartisshowninFigure8a.
flow chart is shown in Figure 8a.
(a) (b)
Figure8. FlowFicghuarret o8f. Fthloewm cohsatrcto omf mthoen mlyousts ceodmumnsounplyer uvsiseedd usncshuepmeervs,is(ead) usscehethmeecsh. angeanalysis
methodandsampleselectionstrategy,(b)baseonthelatentchangemap.
It can be seen that there are two change detection stages in this scheme. The first stage, i.e., pre-
classiIfticcaatniobne, sies eunstuhaalltyt hseimrepalree btwuto wchoratnhg setdudetyeicntgio, nanstda gmesosint othf itshsecmhe amree .uTnhseupfierrsvtissteadg em,ie.eth.,opdrse,-
wclahsiscihfi ccaanti obne ,imispulesumaelnlytesdim wpitlhe dbiufftewreonrcteh asntauldyysiisn agn,dan cdlumsteorsitnogf [1th01em], saurceh uans sKu-pmeeravnisse [d16m2]e, tfhuozdzys,
wc-mhiechancsa n(FbCeMim) p[9le0m,99e,n1t0e0d,1w11i,t1h51d,1iff 6e0r,1e6n5c,e17a8n–a1l8y1s]i,s sapnadtiacll uFstCeMrin g[10[120,115],4]s,u ochr ahsieKra-rmcheiacnasl [F1C6M2],
[f2u1z,z1y13c]-.m Tehains sst(aFgCe Min) s[o9m0,e9 9w,1o0r0k,1s 1a1r,e1 5im1,1p6le0m,16e5n,t1e7d8 –b1y8 1th],ressphaotlida lanFaClMysis[ 1[0128,,13594],] ,saolirenhciyer aanrcahlyicsaisl
[F7C8M], o[2r 1w,11el3l]-.deTshigisnesdta grueliens s[o3m8,8e3w,8o4,r1k2s4,a1r4e8,i1m8p2,l1e8m3e].n tAefdtebr yotbhtraeisnhinogld haingahl-ycsoinsfi[d18e,n3c9e] ,cshaalinegnecdy
oanr/aalnydsi usn[c7h8a],nogredw sealml-dpelessig, tnheed ArIu mleosd[e3l8 c,a8n3, 8b4e, 1tr2a4i,n1e4d8 ,i1n8 2a, s1u83p]e.rvAisfetde rmoabntnaeinr ifnogr chhiagnhg-ceo dnefitedcetniocne
icnh athneg esdecoorn /adn sdtaugnec. hManogreeodvsearm, apnloetsh,ethr ecoAmImmoondleyl cuasnedb eutnrsauinpeedrviinseads uscpheermvies eids bmaasendn eornf othrec hlaatnegnet
cdheatencgtieo nmianpt,h eass eschoonwdnst ainge .FiMguorreeo 8vbe.r ,Iann oatdhderitcioonm mtoo tnhlye upsreed-turanisnuepde rmviosdedels cohbetamineeids bbayse dtraonnstfheer
lleaaternntincgh,a int gceanm baep ,gaesnsehraotwedn biny Faing uurnes8ubp.eIrnviasdedd iAtioI nmtoodtehle (pe.rge.-,t rAaEinse),d amndo dtheel ofibntaali ncehdanbgyet rmanapsf eisr
tlehaernn ginegn,eirtacteadn bbye ugseinnegr aat ecldubstyerainngu anlsguoprietrhvmis e[2d3A,7I9,m98o,1d0e7l,(1e5.7g,.1,6A3E,1s8)4,]a.n dthefinalchangemapis
thenAgeltnheoruatgehd ubnysuuspienrgviasecdlu cshtearningge adlegtoercittihomn d[2o3e,s7 9n,o9t8 r,1e0q7u,1ir5e7 l,a1b63e,l1e8d4 t]r.aining samples, sometimes
the laAcklt hoof upgrihoru knnsouwpelervdigsee dmcahkaens gite udnestuecittaiobnled foore schnaontgree qdueitreectlaiobne liendvotrlaviinnign sgesmamanptilce sin,sfoormmeatitmioens.
Wtheealakclyk oafnpdr isoermkin-osuwpleedrvgiesemda skcehseimtuens suusitea binleafcocrucrahtaen goer dinesteucftfiiocnienintv loalbveinlegds esmamanptliecs inafso ram partiioorni.
Wkneoawkllyedagned tos esmoliv-esu tpheisr vpirsoebdlesmch, ewmheischu csaeni nbaec cimurpalteemoerntiendsu w ffi itchie lnatbelal baeglgedregsaatmiopnl e[s97a]s, iateprartiiovrei
lkenaornwinlegd [g5e8,t1o8s5o],l vdeeethpi sgepnreorbalteimve, mwohdicehlsc [a1n86b]e (ismeep Sleemctieonnt e5d.6w foitrh al amboelrea gdgertaeiglaedti ornev[i9e7w],),i tsearmatpivlee
gleeanrenriantgio[n5 8s,t1r8a5te],gdieese [p15g6e]n, eorra ntiovveeml coodste lfsu[n1c8t6io]n(sse [e36S,e1c8t7io].n 5.6foramoredetailedreview),sample
generationstrategies[156],ornovelcostfunctions[36,187].
5. Mainstream Networks in AI
5. MainstreamNetworksinAI
Section 4 summarizes general AI-based change detection frameworks, but the detailed
Section4summarizesgeneralAI-basedchangedetectionframeworks,butthedetailedintroduction
introduction of their feature extractors and classifiers are not provided. In this section, the various
oftheirfeatureextractorsandclassifiersarenotprovided. Inthissection,thevariousnetworkstructures
network structures in AI used for change detection are specifically analyzed. At present, they mainly
inAIusedforchangedetectionarespecificallyanalyzed. Atpresent,theymainlyincludeautoencoders
include autoencoders (AEs), deep belief networks (DBNs), CNNs, recurrent neural networks (RNNs),
(AEs),deepbeliefnetworks(DBNs),CNNs,recurrentneuralnetworks(RNNs),pulsecoupleneural
pulse couple neural networks (PCNNs), and generative adversarial networks (GANs), as can be seen
networks(PCNNs),andgenerativeadversarialnetworks(GANs),ascanbeseeninFigure9. Inaddition,
in Figure 9. In addition, other networks or methods in AI used for change detection have also been
othernetworksormethodsinAIusedforchangedetectionhavealsobeensummarizedbriefly.
summarized briefly.
5.1. Autoencoder
ThebasicstructureoftheAEisshowninFigure9a. Itmainlyincludestwoparts: anencoderand
adecoder. Theencoderencodestheinputvectorxtogetlatentfeaturesh(x),whichcanbeformulated
as: h(x) =f(Wx+b). Thedecoder,whichcanbeformulatedas:(cid:101)x=f(W (cid:48) h(x)+b (cid:48) ),reconstructsthe
learnedlatentfeaturestooutputavector(cid:101)xthatshouldbeascloseaspossibletotheoriginalx. Wand
baretrainableparametersandcanbeobtainedthroughunsupervisedschemes. Intuitively,anAEcan
beusedforfeaturedimensionalityreduction,similartoPCA,butitsperformanceisbetterduetothe
strongfeaturelearningcapabilitiesoftheneuralnetwork. Thus,itiswidelyusedinchangedetection
tasksasthefeatureextractor. ThecommonlyusedAEmodelsarestackedAEs[97,98,104],stacked
denoisingAEs[16,101,106,121–123,151,160,188],stackedfisherAEs[189],sparseAEs[80],denoising
RemoteSens.2020,12,1688 15of35
AEs [102], fuzzy AEs [105], and contractive AEs [99,103]. These AEs preserve spatial information
byexpandingpixelneighborhoodsintovectors,whileconvolutionalAEsareimplementeddirectly
throughconvolutionkernels[170,190]. Accordingtoitscharacteristics,AEscanbeusedtoimplement
changedetectioninanunsupervisedmannerandperformwell.
Remote Sens. 2020, 12, x FOR PEER REVIEW 15 of 36
(a) (b)
(c) (d)
(e) (f)
FFiigguurree 99. .ScShcehmemataict idcidagiargamra mof ogfengeernaelr anletnweotwrko rakrcahrictehcittuecretus riens AinI uAsIedu sfeodr cfohrancghea ndgeetedcteitoenc:t i(oan) :
a(ua)toaeuntcooednecor d(eArE()A; E(b);) (dbe)epd ebeepliebfe lnieeftwnoertwk o(DrkBN(D);B N(c)); c(ocn)vcoolnuvtioolnuatilo nneaulrnael unreatlwnoertkw (oCrkNN(C);N (Nd)) ;
r(edc)urrerceunrtr neneutnraelu nraeltwneotrwko (rRkN(RNN);N (e);) (peu)plsuel cseoucopulep nleenuerualr anlentwetworokr k(P(CPCNNNN); )(;f()f )ggeneneeraratitvivee aaddvveerrssaarriiaall
nneettwwoorrkkss ((GGAANNss))..
5.2. DeepBeliefNetwork
5.1. Autoencoder
ADBNisagenerativegraphicalmodelandlearnstoprobabilisticallyreconstructitsinputs. Itcan
The basic structure of the AE is shown in Figure 9a. It mainly includes two parts: an encoder and
a
b e
d
f
e
o
c
r
o
m
de
e
r
d
.
b
T
y
he
s t
e
a
n
ck
co
in
d
g
er
m
e
u
n
l
c
ti
o
p
d
le
es
s i
t
m
he
p l
i
e
np
an
u
d
t v
u
e
n
c
s
t
u
o
p
r
e𝒙rv i
t
s
o
e d
ge
n
t
e t
l
w
at
o
en
rk
t
s
fe
su
at
c
u
h
re
a
s
s r𝒉e(s𝒙tr)i
,
c t
w
ed
hi
B
ch
ol t
c
z
a
m
n
a
b
n
e
n
f
m
or
a
m
ch
u
i
l
n
a
e
te
s
d
( R
a
B
s:
M 𝒉s()𝒙o)r=AE𝒇s(.𝑾A𝒙s+sh𝒃o)w
. T
n
h
in
e
F
d
i
e
g
c
u
o
r
d
e
e
9
r,
b
w
,a
h
D
ic
B
h
N
ca
c
n
o n
b
s
e
i s
f
t
o
s
r
o
m
f
u
m
la
u
t
l
e
t
d
ip l
a
e
s:
l a𝒙̃ye=rs𝒇o(f𝑾h′i𝒉d(d𝒙e)n+u𝒃ni′t)s
,
,
r
w
ec
it
o
h
ns
c
t
o
r
n
u
n
ct
e
s
c t
t
i
h
o
e
n
l
s
ea
b
r
e
n
tw
ed
e e
la
n
te
t
n
h
t
e
f
l
e
a
a
y
t
e
u
r
r
s
e
.
s
H
to
o
o
w
u
e
t
v
p
e
u
r
t
,
a
it s
ve
u
c
n
t
i
o
t
r
s w𝒙̃ it
t
h
h
i
a
n
t s
th
h
e
ou
sa
ld
m
b
e
e
l a
as
y e
c
r
lo
a
s
r
e
e
a
n
s
o
p
t
o
c
s
o
s
n
ib
n
l
e
e
c
t
t
o
e d
th
t
e
o
o
e
r
a
i
c
g
h
in
o
a
t
l
h e𝒙r
.
a𝑾nd
a
e
n
a
d
ch 𝒃h i
a
d
r
d
e
e
t
n
ra
l
i
a
n
y
a
e
b
r
l
s
e
e
p
rv
ar
e
a
s
m
as
et
t
e
h
r
e
s
v
a
i
n
s
d
ib
c
le
an
la
b
y
e
e r
o
f
b
o
t
r
ai
t
n
h
e
e
d
n
t
e
h
x
r
t
o
.
u
A
g
s
h
a
u
f
n
e
s
a
u
tu
p
r
e
e
rv
ex
is
t
e
r
d
ac
s
t
c
o
h
r,
e
i
m
tc
e
a
s
n
.
be trained greedily, i.e., one layer at a time, and appears in many unsupervised change detection
Intuitively, an AE can be used for feature dimensionality reduction, similar to PCA, but its
methods[23,37,157,183]. Ontheotherhand,thedeepBoltzmannmachine(DBM),asagraphsimilar
performance is better due to the strong feature learning capabilities of the neural network. Thus, it is
toDBNbutundirected,canalsoachievesuchafunction[182].
widely used in change detection tasks as the feature extractor. The commonly used AE models are
stacked AEs [97,98,104], stacked denoising AEs [16,101,106,121–123,151,160,188], stacked fisher AEs
5.3. ConvolutionalNeuralNetwork
[189], sparse AEs [80], denoising AEs [102], fuzzy AEs [105], and contractive AEs [99,103]. These AEs
preseDrveee pspfeaatitaulr einsfeoxrtmraacttieodn bbyyd eexeppanneduirnagl npeixtwelo nrkesigchabnobrehodoivdisd eindtoin tvoectwtoorsc, awtehgiolrei ecsoancvcoolrudtiinognatol
AwEhse tahreer imsppalteiamlerenltaetdio dnisrheicptlsya trhercooungshid ceornedv.oOluntieotny kpeerunseelss [o1n7e0-,d1i9m0]e.n Asicocnoardldinagta toa sitisn cphuatr(aec.tge.,riDstBicNs,s
AEs can be used to implement change detection in an unsupervised manner and perform well.
5.2. Deep Belief Network
A DBN is a generative graphical model and learns to probabilistically reconstruct its inputs. It
can be formed by stacking multiple simple and unsupervised networks such as restricted Boltzmann
machines (RBMs) or AEs. As shown in Figure 9b, a DBN consists of multiple layers of hidden units,
RemoteSens.2020,12,1688 16of35
andAEs). Theirinputisacolumnvectorconvertedfromtheinputimagepatchthatlosestheintact
spatialinformation. Theotherusestwo-dimensionaldataasinput,consideringthespatialrelationship
anditstypicalrepresentativeisCNN.AsshowninFigure9c,itdetectsfeatureshierarchicallythrough
localconnectionsandsharedweightandisclosertothehumanvisualperceptionmechanism. Forthose
unfamiliarwithCNNs,anexcellentbookbyGoodfellowetal. canbefoundin[191].
Duetoitsstrongabilitytoautomaticallylearndeepfeatures,theCNNhasachievedasatisfactory
performance in various image-processing tasks. Many classic CNNs and their improvements are
usedasclassifiersorfeatureextractorsforchangedetection,suchasVGGNet[78,86,119,140,164,168],
CaffeNet[174],SegNet[192],UNet[169,193],InceptionNet[67],andResNet[194,195]. Nevertheless,
mostofthenetworkstructuresintheliteraturearenewlydesigned,andaCNN,generally,consists
ofaninputlayerandaseriesofconvolutionallayers,poolinglayers,activationfunctions,andfully
connectedlayers. However,toachievespecialfunctions,theCNNsintegratesomespecialstructures
forchangedetection. Forinstance,theregionCNN(R-CNN),primitivelydesignedforobjectdetection
inCV,containsaregion-proposalsstructuretopredicttheregionsofthechangedobjects[87,196,197].
ThePCANet,withitsconvolutionfilterbankschosenfromPCAfilters,isabletoreducetheinfluenceof
specklenoiseandhasbeenusedinSARimagechangedetection[178,180]. Morerecentworkproposes
a kernelPCA convolutionto extract representative spatial–spectralfeaturesfromRS images inan
unsupervisedmanner[163].
Inconclusion, theuseofCNNsenablesthechangedetectionmethodtoreachthestateofthe
art,butthereisnosystematicwayyettodesignand/ortrainthenetwork,whichisalong-standing
problemintheRScommunity.
5.4. RecurrentNeuralNetwork
Obviously,theinputforchangedetectionincludestwoormoreperiodsofdata,sothechange
detection task can be converted into a process of obtaining change information directly from the
multi-periodsequencedata. RNN,asamemorynetworkwhoseinputissequencedata,isverysuitable
forthissituation. AsshowninFigure9d,itscorepartisadirectedgraphthatcanbeunfoldtoachain,
withunits(i.e.,RNNcells)linkedinsequence. AnRNNcellhastwoinputs: oneisthecurrenttime
inputx ,whichisusedtoupdatethestateinrealtime,andtheotheristhestateofthehiddenlayer
t
h t−1 attheprevioustime,whichisusedtorememberthestate. Thenetworkatdifferenttimesshares
thesamesetofparametersF.
Alongshort-termmemory(LSTM)network,aspecialRNNthatalleviatestheproblemofgradient
disappearanceandgradientexplosionduringlongsequencetraining,hasbeenemployedasatemporal
module (see Section 4.3) in change detection tasks [14,38,53,64,74]. In [51], the authors used an
improvedLSTMnetworktoacquireandrecordthechangeinformationofmulti-temporalRSdata.
Advantageously,thetrainedmodelcouldbetransferredtootherdatadomains;thatis,ithasagood
generalizationability. Further,in[52],basedonthesameidea,i.e.,knowledgetransfer,theauthors
proposeanRNN-basedframeworktodetectannualurbandynamicsoffourcities. Thesemethodscan
helptoaddresstheproblemoftemporalspectralvarianceandinsufficientsamplesinthelong-term
detectionofurbanchange.
5.5. PulseCoupleNeuralNetwork
ThePCNNisabionicneuralnetworkinspiredbythevisualcortexofmammals. Unliketraditional
neuralnetworks,itdoesnotrequirealearningandtrainingstagetoextracteffectiveinformationfrom
verycomplexbackgrounds,whichmeansthatitisunsupervisedandcaneasilybeusedasafeature
extractor. AsshowninFigure9e,itmainlyconsistsofthreeparts: areceivedfield,amodulationfield,
andapulsegenerator. APCNNreceivesatwo-dimensionalinputimage,andeachneuroncorresponds
toonepixelintheimage. Thevalueofeachpixelservesasanexternalstimulusforeachneuron,andits
connectedneighboringneuronsprovidelocalstimuli. Theexternalandlocalstimuliarecombinedin
amodulationfieldandapulsegeneratortoproduceapulsedoutput. Asthenumberofiterations
RemoteSens.2020,12,1688 17of35
increases,thePCNNgeneratesapulsesequencethatcanbeusedforimagesegmentationandfeature
extraction[198]and,similarly,forchangedetection[54,66,71,85,124,199–201].
5.6. GenerativeAdversarialNetworks
GANs are algorithmic architectures that use two neural networks, namely, a generator and a
discriminator,tocontestwitheachotherinagametoobtainthebestgenerationanddiscrimination
model[202],asshowninFigure9f. Thegeneratorlearnstogenerateplausibledataasnegativetraining
examplesforthediscriminator,whilethediscriminatorlearnstodistinguishthesefakedatafromreal
data. Therefore,withasmallamountoflabeleddata(i.e.,realdata),awell-performeddiscrimination
model can be trained for change detection [17]. Different from using random Gaussian noises to
generatefakedata[83],theauthorsof[203]usedaCNN-basedgeneratortoproducefakedifference
maps based on the joint distribution of two-period data, which can help to weaken the impact of
thebadpixelsonthenetwork. In[204],theauthorsdesignedaW-Netasageneratortodecreasethe
networkparametersandmakethemeasytotrain,andusedmanymanuallyannotatedsamplesto
improvethereliabilityoftheresults. Morerecentwork[127]proposedaconditionalGANtoachieve
changedetectionofheterogeneousdata,whereatranslationnetworkandanapproximationnetwork
wereusedtotransformtheheterogeneousdataintosamefeaturespace,andthechangemapcould
then be obtained by direct comparison. Similarly, a coupling translation network was employed
in[126]. Formappinglandslides,theauthorsof[93]usedamappinggeneratortotransformthepre-
andpost-landslideimagesintothesamedomain,andaSiamesenetworkwasthenemployedtodetect
landslidechanges.
Toobtainawell-functioningGAN,themethodsneedawell-designedlossfunctionandagood
trainingstrategy;otherwise,themodelresultsmaybeunsatisfactoryduetothefreedomoftheneural
network. Inaddition,realdataareneededtoensurethereliabilityofthenetwork. Thesearechallenges
thatexistinmanypracticalapplications.
5.7. OtherArtificialNeuralNetworksandAIMethods
TherearemanytypesofartificialneuralnetworksinAIandthemainstreamnetworkstructures
used for change detection are described above. In addition, other networks, such as Hopfield
networks [47,48,65,205–207], back propagation networks [42,149,208,209], multilayer perceptrons
(MLPs)[70,210–214],extremelearningmachines[215],andself-organizingmap(SOM)networks[55,
216–221],donotrequirealargenumberoftrainingsamplestolearnhigh-levelabstractfeaturesasdeep
neuralnetworksdo,butduetotheirshallownetworkstructure,lowsamplesizerequirements,and
easytrainingprocess,theyarealsowidelyusedinchangedetectiontasksandcanachievesatisfactory
results. Sincetheycanberegardedastraditionalmachinelearningtechniques,wewillnotmakemore
detailedcommentshereduetospacelimitationsandexistingreviews[7,222,223].
InadditiontotheneuralnetworkinAI,thereareotherAItechniquesusedforimplementing
changedetection. Recently,dictionarylearninghasbeenemployed,anditfocusesonlearninginternal
feature representations from datasets [141,176,224,225], just like AEs. The cellular automata (CA),
aspatially and temporally discrete model inspired by cellular behavior, can help to model future
changes in LULC [226] and predict urban spatial expansion [227]. The development of these AI
techniqueshassignificantlypromotedresearchonchangedetection,whichhelpstodevelopmore
automatic,intelligentandaccuratemethodstomeettheneedsofvariousapplications.
6. Applications
In practical applications, according to the change information, the final change maps can be
groupedintofourtypes, namely, binarymaps, one-classmaps, from–tomaps, andinstancemaps,
ascanbeenseeinFigure10.
Remote Sens. 2020, 12, x FOR PEER REVIEW 18 of 36
AI techniques has significantly promoted research on change detection, which helps to develop more
automatic, intelligent and accurate methods to meet the needs of various applications.
6. Applications
In practical applications, according to the change information, the final change maps can be
RgermooutepSeedns .in20t2o0 f,o12u,r1 6t8y8pes, namely, binary maps, one-class maps, from–to maps, and instance ma1p8so,f a35s
can been see in Figure 10.
Figure10. Schematicdiagramoffourchangemaps. Tomeetdifferentapplicationrequirements,four
Figure 10. Schematic diagram of four change maps. To meet different application requirements, four
differentchangemapscanbeobtainedbydetectingthechangeofthetwo-periodimages,i.e.,(a)binary
different change maps can be obtained by detecting the change of the two-period images, i.e., (a)
maps,(b)one-classmaps,(c)from-tomaps,and(d)instancemaps.
binary maps, (b) one-class maps, (c) from-to maps, and (d) instance maps.
Abinarymapuses1and0toindicatechangeandnochange. Itcontainsanychangesandcannot
A binary map uses 1 and 0 to indicate change and no change. It contains any changes and cannot
provideanadditionaltypeofinformationforthechangedgroundobject. Aone-classmapprovides
provide an additional type of information for the changed ground object. A one-class map provides
single-typechangeinformation,whichindicatestheappearanceanddisappearanceofaspecifictype
single-type change information, which indicates the appearance and disappearance of a specific type
ofgroundobject. Forexample,theresultofbuildingchangedetectionisaone-classmapindicating
of ground object. For example, the result of building change detection is a one-class map indicating
theadditionandremovalofbuildings,whichcanbeusedforurbanmanagement[86]. Afrom–to
the addition and removal of buildings, which can be used for urban management [86]. A from–to
map provides change transfer information, indicating that the ground object is changed from one
map provides change transfer information, indicating that the ground object is changed from one
type to another, and these change types are determined by the classifier [128]. A change instance
type to another, and these change types are determined by the classifier [128]. A change instance map
mapprovidesboundariesforeachchangeinstance,whichcanbetheresultofobject-basedchange
provides boundaries for each change instance, which can be the result of object-based change
detection[89]. ThesechangedetectionmapscanbegeneratedbytrainedAImodelsandusedinvarious
detection [89]. These change detection maps can be generated by trained AI models and used in
applications. Todemonstratethefuturepotentialapplicationdemandsanddevelopmentpossibilities
various applications. To demonstrate the future potential application demands and development
ofAI-basedchangedetectiontechniques,thecurrentattemptsandworkinvariousapplicationfields
possibilities of AI-based change detection techniques, the current attempts and work in various
aresummarizedinthissection. ThedevelopmentofAI-basedchangedetectiontechniqueshasgreatly
application fields are summarized in this section. The development of AI-based change detection
facilitatedmanyapplicationsandhasimprovedtheirautomationandintelligence. MostAI-based
techniques has greatly facilitated many applications and has improved their automation and
changedetectiongeneratesbinarymaps,andthesestudiesonlyfocusonthealgorithmitself,without
intelligence. Most AI-based change detection generates binary maps, and these studies only focus on
a specific application field. Therefore, it can be considered that they are generally suitable for
the algorithm itself, without a specific application field. Therefore, it can be considered that they are
LULCchangedetection. Inthissection,wefocusonthetechniquesthatareassociatedwithspecific
generally suitable for LULC change detection. In this section, we focus on the techniques that are
applications,andtheycanbebroadlydividedintofourcategories:
associated with specific applications, and they can be broadly divided into four categories:
• Urbancontexts: urbanexpansion,publicspacemanagement,andbuildingchangedetection;
• Resources and environment: human-driven environmental changes, hydro-environmental
changes,seaice,surfacewater,andforestmonitoring;
• Naturaldisasters: landslidemappinganddamageassessment;
• Astronomy: planetarysurfaces.
RemoteSens.2020,12,1688 19of35
We provide an overview of the various change detection techniques in the literature for the
differentapplicationcategories. Theworksanddatatypesassociatedwiththeseapplicationsarelisted
inTable2.
Table2. SummaryofmainapplicationsofAI-basedchangedetectiontechniques.
Applications DataTypes
a. Satelliteimages[52,228]
Urbanexpansion
b. SARimages[229]
Publicspacemanagement Streetviewimages[117]
a. Aerialimages[86,89,90]
Urbancontexts
b. Satelliteimages[85,192]
c. Satellite/Aerialimages[88,94]
Buildingchangedetection d. Airbornelaserscanningdataandaerial
images[91]
e. SARimages[112]
f. SatelliteimagesandGISmap[177]
Human-drivenenvironmental
Satelliteimages[69]
changes
Hydro-environmentalchanges Satelliteimages[56]
Resources&environment
Seaice SARimages[171]
Surfacewater Satelliteimages[230,231]
Forestmonitoring Satelliteimages[45,63,150,196,232]
a. Aerialimages[20,93]
Landslidemapping
b. Satelliteimages[129,214,233]
a. Satelliteimages(causedbytsunami[190,234],
particularincident[156],flood[235],or
earthquake[19])
Naturaldisasters b. Aerialimages(causedbytsunami[92])
Damageassessment c. SARimages(causedbyfires[104],or
earthquake[110])
d. Streetviewimages(causedbytsunami[119])
e. StreetviewimagesandGISmap(causedby
tsunami[236])
Astronomy Planetarysurfaces Satelliteimages[170]
Urbanizationisasignificantfactorcausinglandsurfacechange. Asaresultofpopulationgrowth,
theexpansionofurbanizationplaysanimportantroleintransformingnaturallandcoverintourban
facilitiesforpeople. In[52],theauthorsproposedanewframeworkbasedontransferlearningand
anRNNforurbanareaextractionandchangedetection. Itsoverallaccuracyofsingle-yearurban
mapsisapproximately96%amongthefourtargetcities(Beijing,NewYork,Melbourne,andMunich).
Using a genetic-algorithm-evolved ANN [228] or a CNN [229], urban changes were obtained by
takingthedifferenceinthepredictedurbandistributionmaps. Forpublicspacemanagement,change
detectionbasedonstreetviewimagesisagoodwaytoidentifytheencroachmentofpublicspaces.
In[117],aCNN-usingSiamesestructureandtransferlearningachieved98.3%pixelaccuracyinthe
VL-CMU-CDdataset. Inaddition,manystudiesfocusonbuildingchanges. Duetothesmallscale
ofbuildings,changedetectionisusuallycarriedoutbasedonhigh-orvery-high-spatial-resolution
RSdata,suchasaerialphotos[86,90]andsatelliteimagesfromQuickbird[192]orWorldview2[85].
However,duetodifferencesintheexperimentaldata,itisdifficulttoevaluatewhichonehasthebest
performance. AlthoughsomemethodsarebasedontheWHUbuildingdataset[88],unfortunately,
theirexperimentaldataaredifferentwithregardtoarea,whichmakesitdifficulttocomparethem
directly. In[89],theauthorsproposedtwoCNNmodels,amaskR-CNNforobject-basedinstance
segmentationandamulti-scaleCNNforpixel-basedsemanticsegmentation,andtheirintersection
ofunion(IoU)accuracyofbuildingswasmorethan0.83. In[94],theauthorsproposedapyramid
RemoteSens.2020,12,1688 20of35
feature-basedattention-guidedSiamesenetworktodetectbuildingchangesandtheIoUofchange
mapexceeded0.97. Sometimes,theproblemofconstantcloudcoveragepreventsopticalRSimages
frombeingfullyutilized,andSARdatarepresentagoodalternative[112]. Ontheotherhand,toobtain
morebuildinginformationtopromotechangedetection,airbornelaserscanningdata[91]andbuilding
thematicdata[177]canprovide3-Dinformationandaprioriknowledgeofbuildings,respectively,
andprovedtobeeffective.
Land cover changes typically reflect changes in climatology and hydrology. Thus, AI-based
change detection techniques can provide effective methods to monitor changes in resources and
the environment. For example, forest monitoring is usually achieved by detecting changes using
multi-periodLandsatsatelliteimages[45,63,150,196,232]. InadditiontotheLandsatdata,theauthors
of[56]usedanANNtoinvestigateLULCchangesandtheeffectonoutletrunoffbydetectingLULC
changelocations. Surfacewaterisessentialforhumans;usinganANN[230]orCNN[231],itschanges
can be detected effectively. Obtaining sea ice changes is crucial for navigation safety and climate
researchinthepolarregions. Theauthorsof[171]employedatransferlearning-basedframeworkand
aCNNmodeltodetectseaicechangesfromtwo-periodSARimages,andobtainedresultswithkappa
coefficientexceeding94%.
Naturaldisasterisapowerfulagentthatchangestheappearanceofthelandscape. Therefore,
changedetectiontechniquesbasedonRSdataaresignificantmeasurestomonitornaturaldisasters.
Forexample,moreautomaticandaccuratelandslidemappingcanbeachievedthroughCNN-based
changedetectionmethods[20,93,129,233]. Damageassessmentisanimportantapplicationfieldof
changedetection. Afteranaturaldisaster,AI-basedchangetechniquescanhelptoidentifydamaged
areasusingpre-eventandpost-eventdata. Existingresearchmainlyincludestsunamis[92,119,190,234,
236],floods[235],fires[104],andearthquakes[19,110].
Many change detection techniques focus on applications that are closely related to people’s
dailylives,butin[170],anewAI-basedapproachisproposedforplanetarysurfacechangedetection,
employing a transfer learning-based framework and convolutional AE models. The experiments
showedthattheproposedmethodwassuperiortoadifferenceimage-basedmethod.
7. ChallengesandOpportunitiesforAI-BasedChangeDetection
By combining general AI-based change detection frameworks and the network structure
summarized in Sections 4 and 5, change detection for various applications can be implemented.
ThedesignoftheAImodelusuallyneedstoconsiderthemulti-periodinputdatatype,trainingsetsize,
anddesiredchangemap. Specifically,amappingtransformation-basedstructureorpseudo-siamese
structure should be considered first based on heterogeneous data. To obtain from–to change
maps,post-classificationstructureisthebestchoice. Iftrainingsamplesareinsufficient,atransfer
learning-basedstructurecanhelpalleviatethisproblem,andtheuseofAEsandGANscanalsoreduce
the dependence on ground truth. Change detection based on long-term sequence data is usually
implemented using the multi-model integrated structure and an RNN model. A CNN has strong
featureextractioncapability,andisthebestchoicewhentherearesufficienttrainingsamples.
VariousapplicationsofAI-basedchangedetectionhavedemonstratedthatAItechniqueshave
achievedgreatsuccessinthefieldofchangedetectioninRScommunity. However,therearemany
challengesintheprocesses,andtheyrelatetothefollowing:
• Withthedevelopmentofvariousplatformsandsensors,theybringsignificantchallengessuchas
high-dimensionaldatasets(thehighspatialresolutionandhyperspectralfeatures),complexdata
structures(nonlinearandoverlappingdistributions),andthenonlinearoptimizationproblem
(high computational complexity). The complexity of multi-source data greatly contributes to
thedifficultyoflearningrobustanddiscriminativerepresentationsfromtrainingdatawithAI
techniques. Thiscanbeconsideredachallengeofheterogeneousbigdataprocessing;
• ThesupervisedAImethodsrequiremassivetrainingsamples, whichareusuallyobtainedby
time-consumingandlabor-intensiveprocessessuchashumaninterpretationofRSproductsand
RemoteSens.2020,12,1688 21of35
fieldsurveys. ItisabigchallengetoachievearobustmodelofAI-basedmethodswithinsufficient
trainingsamples. UnsupervisedAItechniquesneedtobedeveloped;
• TherearevariousefficientandaccurateAImodelsandframeworks,aswereviewinSections4
and5. Atpresent,researchersconstantlyproposenovelAI-basedchangedetectionapproaches
endlessly. Still,itisalsoagreatchallengetochooseanefficientoneandensureitsaccuracyfor
differentapplications. ThereliabilityofAIneedstobeconsideredinpracticalapplications.
Some researchers have explored solutions to these problems and proposed useful strategies.
Wewilldiscussthemseparatelyandgiveourviews.
7.1. HeterogeneousBigDataProcessing
Heterogeneity is one of the main characteristics of big data and heterogeneous data, causing
problems in the generation and analytics of change detection results [237]. From the data source
perspective,RStechnologycanprovidevariousdatatypesforchangedetection,suchasSAR,GISdata,
high-resolutionsatelliteimages,andvarioustimeandspacemeasureddata. Thesedatawithhigh
variabilityofdatatypesandformatsaredifficulttouseduetomissingvalues,highdataredundancy,
anduntruthfulness. Moreover,thegeneralizationabilityofexistingAImethodsneedstobeimproved
inRSdataprocessing,especiallyinheterogeneousbigdataprocessing[88]. Therefore,inouropinion,
thefollowingaspectsneedfurtherstudy:
• AlthoughsomeAI-basedchangedetectionmethodsbasedonheterogeneousdatahaveachieved
satisfactoryresults, assummarizedinSection3.1.4, thetypesofsensoranddatasizeofthese
studiesarerelativelylimited. Moreover,theymainlyconsiderchangedetectionbetweendifferent
sourcedataratherthanfindingthefusionofdatainthesameperiod. Thefulluseofmulti-source
dataatthesameperiod(e.g.,opticalRSimagesandDEM)anddatafusiontheories(i.e.,mutual
compensationofvarioustypesofdata),combinedwithAItechniques,wouldhelpimprovethe
accuracyofchangedetectionsufficiently;
• Since current change detection methods mainly depends on the detection of 2D information,
withthedevelopmentof3Dreconstructiontechniques,using3Ddatatodetectchangesinbuildings,
etc.,isalsoadirectionoffuturedevelopment[6]. Amongsuchtechniques,3Dreconstruction
basedonobliqueimagesorlaserpointclouddataand3Dinformationintegrationbasedonaerial
imageryandground-levelstreetviewimagery(i.e.,air–groundintegration)arethehottopicsof
research. TherearestillnoeffectiveAItechniquesthatimplement3Dchangedetection;
• The processing of RS big data requires a large amount of computing resources, limiting the
implementationoftheAImodel. Forexample,theprocessingoflarge-formatdatausuallyneeds
tobeprocessedinblocks,whicheasilyleadstoedgeproblems. Thelargeamountofdatameans
thatlargetrainableparametersintheAImodelarerequired,resultinginadifficulttrainingprocess
andconsumingahighamountofcomputingresources. Therefore,itisnecessarytobalancethe
amountofdataandthenumberoftrainableparameters. Theyposechallengestothedesignof
AI-basedchangedetectionapproaches.
Inshort,heterogeneousbigdatashouldbeconsideredwhendesigningAImodelsforchange
detectionsothatitcanbepracticallyusedforRSbigdataprocessing,whichisworthpursuing.
7.2. UnsupervisedAI
Althoughdomainknowledgecanbeusedtohelpdesignrepresentationsintraditionalmachine
learning methods, the quest for AI is motivating the design of more powerful unsupervised
representation-learningalgorithms[238]. ThisisbecauseunsupervisedAIpossessesthecapacityof
learninghierarchyfeaturesdirectlyfromthedataitself,andcanbeusedtomakedata-drivendecisions.
TheresearchonunsupervisedAIcanbeconsideredinthefollowingaspects:
RemoteSens.2020,12,1688 22of35
• DuetothelackoflabeledsamplestotrainefficientAImodelsinthepastfewyears,manyresearchers
havedevotedgreateffortstotheseproblemsandhaveconsistentlyproducedimpressiveresults.
NewunsupervisedAItechniquesareconstantlyemerging, includingGAN,transferlearning,
andAEs,assummarizedinSection4.4. Althoughthesetechniquesalleviatethelackofsamplesto
acertainextent,thereisstillroomforimprovement;
• Changedetectionisgenerallyregardedasalow-likelihoodproblem(i.e.,theunchangedinthe
changemapismuchlargerthanthechanged),withtheuncertaintyofthechangelocationand
direction. ThecurrentunsupervisedAItechniquesdonoteasilysolvethisproblemduetothe
lackofpriorknowledge. ExcludingsupervisedAI,weakly-andsemi-supervisedAItechniques
are feasible solutions, but further research is needed to improve performance. Nevertheless,
pureunsupervisedAItechniqueforchangedetectionshouldbetheultimategoal;
• One of the reasons for studying unsupervised AI techniques is the lack of training samples,
i.e.,priorknowledge. ConsideringthattheInternethasenteredtheWeb2.0era(emphasizing
user-generated content, ease of use, participatory culture and interoperability for end users),
using crowd-source data as a priori knowledge is a good alternative solution. For example,
OpenStreetMap[32],afreewikiworldmap,canprovidealargeamountofannotationdatalabeled
byvolunteersforthetrainingofAImodels. Althoughthelabelprecisionofsomecrowd-sourced
data is not high, the AI model can also be trained in a weakly supervised manner to achieve
changedetection.
Ontheotherhand,giventhecurrenttrendsinCV,unsupervisedAItechniqueswillremainahot
researchfieldandevenmorepopularinchangedetectionaswell.
7.3. ReliabilityofAI
AlthoughmanychangedetectionframeworksusingAIpresentthemodelstructure,theirtrainable
parametersareopaque,likeblackboxes,whichmakeitdifficulttodeterminewhytheydowhatthey
do or how they work [239]. The reliability of AI aims to develop techniques to help improve the
reliabilityandinterpretabilityofthechangedetectionmethods. Therefore,itisnecessarytodevelop
robustAIandinterpretableAIforchangedetection. Therelevanttheoreticalliteraturecanbefound
in[240,241]. Weonlydiscussstrategiesthatcanbeusedtoimprovethereliabilityofchangedetection
resultsfromthefollowingaspects:
• Strategy 1: Reduce errors caused by data sources, such as using preprocessing (e.g., spectral
andradiometriccorrection)toreducetheuncertaintyofdatacausedbygeometricerrorsand
spectraldifferences,orfusingmultipledatatoimprovethereliabilityoftheoriginaldata,thereby
improvingthereliabilityofthechangedetectionresults. Todate,therehavebeensomestudies
consideringtheimpactofregistration[242]andalgorithmfusion[243];
• Strategy2: ImprovetheinterpretabilityofAImodelsthroughasub-modularmodelstructure,
whichcanhelptounderstandtheoperationprincipleoftheentireAImodelbyunderstandingthe
functionofeachsub-module. Forexample,theregion-proposalscomponentinR-CNNcanbe
clearlyunderstoodasageneratortopredicttheregionsoftheobjects;
• Strategy3: ImprovetherobustnessofAImodelsbyintegrationofmultiplealgorithmsandresults.
Ensemblelearningisagoodsolution[15,244],whichcanimprovetheaccuracyofthefinalresult
byusingtheresultsofmultiplemodels;
• Strategy 4: Improve the practicality of the AI model results by integrating post-processing
algorithms,suchastheMarkovrandomfield[245],theconditionalrandomfield[246],andlevel
setevolution[247],whichcanhelpremovenoisepointsandprovideaccurateboundaries. Thisis
criticalforsomecartographicapplications;
• Strategy5: Improvethefinenessofchangemapsthroughrefineddetectionunits. Accordingto
thedetectionunitofchangedetection,itcanbedividedintoscenelevel,patchorsuper-pixellevel,
pixellevelandsub-pixellevelfromcoarsetofine. Fromtheaspectofreliability,sub-pixellevelis
RemoteSens.2020,12,1688 23of35
thebestchoicebecauseitalleviatestheproblemofmixedpixelsinRSimages. However,thiseasily
leadstohighcomputationalcomplexity. Therefore,usingdifferentdetectionunitsaccordingto
differentlandcovertypesisthebestsolution,whichrequiresawell-designedAImodel;
• Strategy6: Improvetherepresentationofchangemapsbydetectingchangesineachinstance.
As we introduced in Section 6, the change maps can be grouped into binary maps, one-class
maps, from–tomaps, andinstancemaps. Theinstancechangemapismorepracticalbutstill
lacks research. It can provide change information for each instance, and is more reflective of
real-worldchanges. Moreover,itcanavoidthelimitationofthebinarymapwithoutsemantic
informationandtherestrictionofthefrom–tomapbytheclassificationsystem,therebyimproving
thereliabilityofthefinalresult.
When using AI techniques for change detection, factors that affect the reliability of data
preprocessing, model training, change feature extraction, and accuracy assessment should be
considered. This aims toward the most reasonable AI framework to improve the reliability of
changedetectionresults.
Inthissection,asummaryofthechallengesandopportunitiesforAI-basedchangedetection
techniqueshasbeendelineatedandwehaveputforwardourprospects. ThedevelopmentofAI-based
changedetectiontechniquesdependsonthefutureendeavoronovercomingthesechallenges;theefforts
andinnovationsofresearcherswouldpushforwardfurthersuccessesofthetechniques.
8. Conclusions
Thisreviewpresentsthelatest methods, applications, andchallenges ofthe AI-basedchange
detection techniques. For beginners, the implementation process of AI-based change detection is
introduced. Consideringthatthevalidityoftrainingdataisoneofthemajorchallenges,thecommonly
useddatasourcesandexistingdatasetsusedforchangedetectionwerefullysurveyed. Althoughthe
currentpublicdatasetshaveincreasedsignificantly,openlylabeleddatasetsforchangedetectionare
stillscarceanddeficient,whichrequiresthejointeffortsoftheRScommunity. Thesystematicanalysis
ofthegeneralnetworkframeworksandcommonlyusednetworksinAIadoptedforchangedetection
showsthatgreatprogresshasbeenmadeinthecombinationofAIforchangedetection,butthereare
stillmanychallengesinchangedetectionwithheterogeneousbigdataprocessing,unsupervisedAI,
andthereliabilityofAI.Thismeansthatfurtherresearchneedstobepushedforward. Thisreview
offersaclearerorganizationandwillhelpresearchersunderstandthisfield.
AuthorContributions: Allauthorscontributedinasubstantialwaytothemanuscript. W.S.andM.Z.conceived
thereview. M.Z.wrotethemanuscript. M.Z.andR.Z.contributedtothediscussionofthereview. M.Z.,R.Z.,S.C.
andZ.Z.madecontributiontothereviewofrelatedliterature. Allauthorsdiscussedthebasicstructureofthe
manuscript. W.S.designedtheoverallstructureofthereview,reviewedthemanuscriptandsupervisedthestudy
forallthestages. Allauthorshavereadandagreedtothepublishedversionofthemanuscript.
Funding: ThisresearchwasfundedbytheMinistryofScienceandTechnologyofthePeople’sRepublicofChina,
GrantNo.2017YFB0503604.
Acknowledgments: The authors sincerely appreciate that academic editors and reviewers give their help
commentsandconstructivesuggestions.
ConflictsofInterest: Theauthorsdeclarenoconflictofinterest.
References
1. Singh, A. Digital change detection techniques using remotely sensed data. Int. J. Remote Sens. 1989,
10,989–1003. [CrossRef]
2. Liu,S.;Marinelli,D.;Bruzzone,L.;Bovolo,F.AReviewofChangeDetectioninMultitemporalHyperspectral
Images: CurrentTechniques,Applications,andChallenges. IEEEGeosci. RemoteSens. Mag. 2019,7,140–158.
[CrossRef]
3. Tewkesbury,A.P.;Comber,A.;Tate,N.J.;Lamb,A.;Fisher,P.F.Acriticalsynthesisofremotelysensedoptical
imagechangedetectiontechniques. RemoteSens. Environ. 2015,160,1–14. [CrossRef]
RemoteSens.2020,12,1688 24of35
4. Lu, D.; Mausel, P.; Brondizio, E.; Morán, E. Change detection techniques. Int. J. Remote Sens. 2004,
25,2365–2401. [CrossRef]
5. Chen,G.;Hay,G.J.;DeCarvalho,L.M.T.;AWulder,M.Object-basedchangedetection. Int. J.RemoteSens.
2012,33,4434–4457. [CrossRef]
6. Qin,R.;Tian,J.;Reinartz,P.3Dchangedetection–Approachesandapplications. ISPRSJ.Photogramm. Remote
Sens. 2016,122,41–56. [CrossRef]
7. Hussain,M.;Chen,D.M.;Cheng,A.;Wei,H.;Stanley,D.Changedetectionfromremotelysensedimages:
Frompixel-basedtoobject-basedapproaches. ISPRSJ.Photogramm. RemoteSens. 2013,80,91–106. [CrossRef]
8. Kaplan,A.;Haenlein,M.Siriinmyhand: Who’sthefairestintheland? Ontheinterpretations,illustrations,
andimplicationsofartificialintelligence. Bus. Horiz. 2019,62,15–25. [CrossRef]
9. Zhang, W.; Lu, X. The Spectral-Spatial Joint Learning for Change Detection in Multispectral Imagery.
RemoteSens.2019,11,240. [CrossRef]
10. Fang,B.;Pan,L.;Kou,R.DualLearning-BasedSiameseFrameworkforChangeDetectionUsingBi-Temporal
VHROpticalRemoteSensingImages. RemoteSens. 2019,11,1292. [CrossRef]
11. Zhong,Y.;Ma,A.;Ong,Y.-S.;Zhu,Z.;Zhang,L.Computationalintelligenceinopticalremotesensingimage
processing. Appl. SoftComput. 2018,64,75–93. [CrossRef]
12. Ma, L.; Liu, Y.; Zhang, X.; Ye, Y.; Yin, G.; Johnson, B.A. Deep learning in remote sensing applications:
Ameta-analysisandreview. ISPRSJ.Photogramm. Remote. Sens. 2019,152,166–177. [CrossRef]
13. Ball,J.E.;Anderson,D.T.;Chan,C.S.Comprehensivesurveyofdeeplearninginremotesensing: Theories,
tools,andchallengesforthecommunity. J.Appl. RemoteSens. 2017,11,1. [CrossRef]
14. Chen,H.; Wu,C.; Du,B.; Zhang,L.; Wang,L.ChangeDetectioninMultisourceVHRImagesviaDeep
SiameseConvolutionalMultiple-LayersRecurrentNeuralNetwork. IEEETrans. Geosci. RemoteSens. 2020,
58,2848–2864. [CrossRef]
15. Wang,X.;Liu,S.;Du,P.;Liang,H.;Xia,J.;Li,Y.Object-BasedChangeDetectioninUrbanAreasfromHigh
SpatialResolutionImagesBasedonMultipleFeaturesandEnsembleLearning. RemoteSens. 2018,10,276.
[CrossRef]
16. Zhang,P.;Gong,M.;Su,L.;Liu,J.;Li,Z.Changedetectionbasedondeepfeaturerepresentationandmapping
transformationformulti-spatial-resolutionremotesensingimages. ISPRSJ.Photogramm. RemoteSens. 2016,
116,24–41. [CrossRef]
17. Zhao,W.;Mou,L.;Chen,J.;Bo,Y.;Emery,W.J.IncorporatingMetricLearningandAdversarialNetworkfor
SeasonalInvariantChangeDetection. IEEETrans. Geosci. RemoteSens. 2020,58,2720–2731. [CrossRef]
18. Zhao,J.J.;Gong,M.G.;Liu,J.;Jiao,L.C.Deeplearningtoclassifydifferenceimageforimagechangedetection.
InProceedingsofthe2014InternationalJointConferenceonNeuralNetworks,Beijing,China,6–11July
2014;IEEE:NewYork,NY,USA,2014;pp.397–403.
19. Ji,M.;Liu,L.;Du,R.;Buchroithner,M.F.AComparativeStudyofTextureandConvolutionalNeuralNetwork
FeaturesforDetectingCollapsedBuildingsAfterEarthquakesUsingPre-andPost-EventSatelliteImagery.
RemoteSens. 2019,11,1202. [CrossRef]
20. Lei,T.;Zhang,Y.;Lv,Z.;Li,S.;Liu,S.;Nandi,A.K.LandslideInventoryMappingFromBitemporalImages
UsingDeepConvolutionalNeuralNetworks. IEEEGeosci. RemoteSens. Lett. 2019,16,1–5. [CrossRef]
21. Geng, J.; Ma, X.; Zhou, X.; Wang, H. Saliency-Guided Deep Neural Networks for SAR Image Change
Detection. IEEETrans. Geosci. RemoteSens. 2019,57,7365–7377. [CrossRef]
22. Zhan,Y.;Fu,K.;Yan,M.;Sun,X.;Wang,H.;Qiu,X.ChangeDetectionBasedonDeepSiameseConvolutional
NetworkforOpticalAerialImages. IEEEGeosci. RemoteSens. Lett. 2017,14,1845–1849. [CrossRef]
23. Cao,G.;Wang,B.;Xavier,H.-C.;Yang,D.;Southworth,J.Anewdifferenceimagecreationmethodbasedon
deepneuralnetworksforchangedetectioninremote-sensingimages. Int. J.RemoteSens. 2017,38,7161–7175.
[CrossRef]
24. Gong,M.;Zhao,J.;Liu,J.;Miao,Q.;Jiao,L.ChangeDetectioninSyntheticApertureRadarImagesBasedon
DeepNeuralNetworks. IEEETrans. NeuralNetw. Learn. Syst. 2016,27,125–138. [CrossRef][PubMed]
25. TensorFlow. Availableonline: https://www.tensorflow.org/(accessedon5May2020).
26. Keras. Availableonline: https://keras.io/(accessedon5May2020).
27. Pytorch. Availableonline: https://pytorch.org/(accessedon5May2020).
28. Caffe. Availableonline: https://caffe.berkeleyvision.org/(accessedon5May2020).
RemoteSens.2020,12,1688 25of35
29. Ghouaiel,N.;Lefevre,S.Couplingground-levelpanoramasandaerialimageryforchangedetection. Geospat.
Inf. Sci. 2016,19,222–232. [CrossRef]
30. Regmi, K.; Shah, M. Bridging the Domain Gap for Ground-to-Aerial Image Matching. arXiv 2019,
arXiv:1904.11045.
31. Kang,J.;Körner,M.;Wang,Y.;Taubenbock,H.;Zhu,X.X.Buildinginstanceclassificationusingstreetview
images. ISPRSJ.Photogramm. Remote. Sens. 2018,145,44–59. [CrossRef]
32. OpenStreetMap. Availableonline: http://www.openstreetmap.org/(accessedon4May2020).
33. ISPRSBenchmarks.Availableonline:http://www2.isprs.org/commissions/comm3/wg4/3d-semantic-labeling.
html(accessedon4May2020).
34. Cordts,M.;Omran,M.;Ramos,S.;Rehfeld,T.;Enzweiler,M.;Benenson,R.;Franke,U.;Roth,S.;Schiele,B.
Thecityscapesdatasetforsemanticurbansceneunderstanding. InProceedingsoftheIEEEConferenceon
ComputerVisionandPatternRecognition,Seattle,WA,USA,27–30June2016;pp.3213–3223.
35. Baumgardner,M.F.;Biehl,L.L.;Landgrebe,D.A.220bandavirishyperspectralimagedataset: June12,1992
indianpinetestsite3. PurdueUniv. Res. Repos. 2015,10,R7RX991C.
36. Li,X.;Yuan,Z.;Wang,Q.UnsupervisedDeepNoiseModelingforHyperspectralImageChangeDetection.
RemoteSens. 2019,11,258. [CrossRef]
37. Huang,F.;Yu,Y.;Feng,T.Hyperspectralremotesensingimagechangedetectionbasedontensoranddeep
learning. J.Vis. Commun. ImageRepresent. 2019,58,233–244. [CrossRef]
38. Song,A.;Choi,J.;Han,Y.;Kim,Y.ChangeDetectioninHyperspectralImagesUsingRecurrent3DFully
ConvolutionalNetworks. RemoteSens. 2018,10,1827. [CrossRef]
39. Wang,Q.;Yuan,Z.;Du,Q.;Li,X.GETNET:AGeneralEnd-to-End2-DCNNFrameworkforHyperspectral
ImageChangeDetection. IEEETrans. Geosci. RemoteSens. 2018,57,3–13. [CrossRef]
40. He,Y.;Weng,Q.HighSpatialResolutionRemoteSensing: Data,Analysis,andApplications;CRCPress: Boca
Raton,FL,USA,2018.
41. Anees,A.;Aryal,J.;O’Reilly,M.M.;Gale,T.;Wardlaw,T.Arobustmulti-kernelchangedetectionframework
fordetectingleafbeetledefoliationusingLandsat7ETM+data. ISPRSJ.Photogramm. RemoteSens. 2016,
122,167–178. [CrossRef]
42. Dai,X.L.;Khorram,S.Remotelysensedchangedetectionbasedonartificialneuralnetworks. Photogramm.
Eng. RemoteSens. 1999,65,1187–1194.
43. Bruzzone,L.;Cossu,R.AnRBFneuralnetworkapproachfordetectingland-covertransitions. InImageand
SignalProcessingforRemoteSensingVii;Serpico,S.B.,Ed.;Spie-IntSocOpticalEngineering: Bellingham,WA,
USA,2002;Volume4541,pp.223–231.
44. Abuelgasim,A.;Ross,W.;Gopal,S.;Woodcock,C.ChangeDetectionUsingAdaptiveFuzzyNeuralNetworks.
RemoteSens. Environ. 1999,70,208–223. [CrossRef]
45. Deilmai, B.R.; Kanniah, K.D.; Rasib, A.W.; Ariffin, A. Comparison of pixel -based and artificial neural
networksclassificationmethodsfordetectingforestcoverchangesinMalaysia. InProceedingsofthe8th
InternationalSymposiumoftheDigitalEarth, UnivTeknologiMalaysia, InstGeospatialSci&Technol,
Kuching,Malaysia,26–29August2013;IopPublishingLtd.: Bristol,UK,2014;Volume18.
46. Feldberg,I.;Netanyahu,N.S.;Shoshany,M.Aneuralnetwork-basedtechniqueforchangedetectionoflinear
featuresanditsapplicationtoaMediterraneanregion. InProceedingsoftheIEEEInternationalGeoscience
andRemoteSensingSymposium,IGARSS,Toronto,ON,Canada,24–28June2002;Volume2,pp.1195–1197.
[CrossRef]
47. Ghosh,A.; Subudhi,B.N.; Bruzzone,L.IntegrationofGibbsMarkovRandomFieldandHopfield-Type
NeuralNetworksforUnsupervisedChangeDetectioninRemotelySensedMultitemporalImages. IEEE
Trans. ImageProcess. 2013,22,3087–3096. [CrossRef]
48. Ghosh,S.;Bruzzone,L.;Patra,S.;Bovolo,F.;Ghosh,A.AContext-SensitiveTechniqueforUnsupervised
ChangeDetectionBasedonHopfield-TypeNeuralNetworks. IEEETrans. Geosci. RemoteSens. 2007,45,
778–789. [CrossRef]
49. Ghosh,S.;Patra,S.;Ghosh,A.Anunsupervisedcontext-sensitivechangedetectiontechniquebasedon
modifiedself-organizingfeaturemapneuralnetwork. Int. J.Approx. Reason. 2009,50,37–50. [CrossRef]
50. Han,M.;Zhang,C.;Zhou,Y.Object-wisejoint-classificationchangedetectionforremotesensingimages
basedonentropyquery-byfuzzyARTMAP.GISci. RemoteSens. 2018,55,265–284. [CrossRef]
RemoteSens.2020,12,1688 26of35
51. Lyu,H.;Lu,H.;Mou,L.LearningaTransferableChangeRulefromaRecurrentNeuralNetworkforLand
CoverChangeDetection. RemoteSens. 2016,8,506. [CrossRef]
52. Lyu,H.; Lu,H.; Mou,L.; Li,W.; Wright,J.S.; Li,X.; Li,X.; Zhu,X.X.; Wang,J.; Yu,L.; etal. Long-Term
AnnualMappingofFourCitiesonDifferentContinentsbyApplyingaDeepInformationLearningMethod
toLandsatData. RemoteSens. 2018,10,471. [CrossRef]
53. Mou,L.C.;Zhu,X.X.Arecurrentconvolutionalneuralnetworkforlandcoverchangedetectioninmultispectral
images. InProceedingsoftheIgarss2018IEEEInternationalGeoscienceandRemoteSensingSymposium,
Valencia,Spain,22–27July2018;IEEE:NewYork,NY,USA,2018;pp.4363–4366.
54. Neagoe, V.E.; Ciotec, A.D.; Carata, S.V. A new multispectral pixel change detection approach using
pulse-coupledneuralnetworksforchangevectoranalysis. InProceedingsofthe2016IEEEInternational
GeoscienceandRemoteSensingSymposium,Beijing,China,10–15July2016;IEEE:NewYork,NY,USA,
2016;pp.3386–3389. [CrossRef]
55. Neagoe,V.E.; Stoica,R.M.; Ciurea,A.I.Amodularneuralnetworkmodelforchangedetectioninearth
observation imagery. In Proceedings of the 2013 IEEE International Geoscience and Remote Sensing
Symposium, Melbourne, Australia, 21–26 July 2013; IEEE: New York, NY, USA, 2013; pp. 3321–3324.
[CrossRef]
56. Nourani,V.;Roushangar,K.;Andalib,G.Aninversemethodforwatershedchangedetectionusinghybrid
conceptualandartificialintelligenceapproaches. J.Hydrol. 2018,562,371–384. [CrossRef]
57. Patra, S.; Ghosh, S.; Ghosh, A. Unsupervised Change Detection in Remote-Sensing Images Using Modified
Self-OrganizingFeatureMapNeuralNetwork;IEEEComputerSoc.: LosAlamitos,CA,USA,2007;p.716.
58. Roy,M.; Ghosh,S.; Ghosh,A.Anovelapproachforchangedetectionofremotelysensedimagesusing
semi-supervisedmultipleclassifiersystem. Inf. Sci. 2014,269,35–47. [CrossRef]
59. Roy,M.;Ghosh,S.;Ghosh,A.ANeuralApproachUnderActiveLearningModeforChangeDetectionin
RemotelySensedImages. IEEEJ.Sel. Top. Appl. EarthObs. RemoteSens. 2013,7,1200–1206. [CrossRef]
60. Sadeghi,V.;Ahmadi,F.F.;Ebadi,H.Anewfuzzymeasurementapproachforautomaticchangedetection
usingremotelysensedimages. Measurement2018,127,1–14. [CrossRef]
61. Seto,K.C.; Liu,W.ComparingARTMAPNeuralNetworkwiththeMaximum-LikelihoodClassifierfor
DetectingUrbanChange. Photogramm. Eng. RemoteSens. 2003,69,981–990. [CrossRef]
62. Varamesh,S.DetectionoflandusechangesinNorthEasternIranbyLandsatsatellitedata. Appl. Ecol.
Environ. Res. 2017,15,1443–1454. [CrossRef]
63. EWoodcock,C.;AMacomber,S.;Pax-Lenney,M.;Cohen,W.B.Monitoringlargeareasforforestchangeusing
Landsat: Generalizationacrossspace,timeandLandsatsensors. RemoteSens. Environ. 2001,78,194–203.
[CrossRef]
64. Mou,L.;Bruzzone,L.;Zhu,X.X.LearningSpectral-Spatial-TemporalFeaturesviaaRecurrentConvolutional
NeuralNetworkforChangeDetectioninMultispectralImagery. IEEETrans. Geosci. RemoteSens. 2018,
57,924–935. [CrossRef]
65. Li, X.; Ling, F.; Du, Y.; Feng, Q.; Zhang, Y. A spatial–temporal Hopfield neural network approach for
super-resolutionlandcovermappingwithmulti-temporaldifferentresolutionremotelysensedimages.
ISPRSJ.Photogramm. RemoteSens. 2014,93,76–87. [CrossRef]
66. Benedetti,A.;Picchiani,M.;DelFrate,F.Sentinel-1andSentinel-2datafusionforurbanchangedetection. In
Proceedingsofthe2018IEEEInternationalGeoscienceandRemoteSensingSymposium,Valencia,Spain,
22–27July2018;IEEE:NewYork,NY,USA,2018;pp.1962–1965.
67. Pomente,A.;Picchiani,M.;DelFrate,F.Sentinel-2changedetectionbasedondeepfeatures. InProceedings
ofthe2018IEEEInternationalGeoscienceandRemoteSensingSymposium,Valencia,Spain,22–27July2018;
IEEE:NewYork,NY,USA,2018;pp.6859–6862.
68. Arabi,M.E.A.;Karoui,M.S.;Djerriri,K.Opticalremotesensingchangedetectionthroughdeepsiamese
network. In Proceedings of the 2018 IEEE International Geoscience and Remote Sensing Symposium,
Valencia,Spain,22–27July2018;IEEE:NewYork,NY,USA,2018;pp.5041–5044.
69. Chen,H.;Hua,Y.;Ren,Q.;Zhang,Y.Comprehensiveanalysisofregionalhuman-drivenenvironmental
change with multitemporal remote sensing images using observed object-specified dynamic Bayesian
network. J.Appl. RemoteSens. 2016,10,16021. [CrossRef]
RemoteSens.2020,12,1688 27of35
70. Pacifici,F.;DelFrate,F.;Solimini,C.; Emery,W.AnInnovativeNeural-NetMethodtoDetectTemporal
ChangesinHigh-ResolutionOpticalSatelliteImagery. IEEETrans. Geosci. RemoteSens. 2007,45,2940–2952.
[CrossRef]
71. Pacifici,F.;DelFrate,F.AutomaticChangeDetectioninVeryHighResolutionImageswithPulse-Coupled
NeuralNetworks. IEEEGeosci. Remote. Sens. Lett. 2009,7,58–62. [CrossRef]
72. Saha,S.;Bovolo,F.;Bruzzone,L.UnsupervisedDeepChangeVectorAnalysisforMultiple-ChangeDetection
inVHRImages. IEEETrans. Geosci. RemoteSens. 2019,57,3677–3693. [CrossRef]
73. Larabi,M.E.A.; Chaib,S.; Bakhti,K.; Hasni,K.; Bouhlala,M.A.High-resolutionopticalremotesensing
imagerychangedetectionthroughdeeptransferlearning. J.Appl. RemoteSens. 2019,13,18. [CrossRef]
74. Liu, R.; Cheng, Z.; Zhang, L.; Li, J. Remote Sensing Image Change Detection Based on Information
TransmissionandAttentionMechanism. IEEEAccess2019,7,156349–156359. [CrossRef]
75. Han,M.;Chang,N.-B.;Yao,W.;Chen,L.-C.;Xu,S.Changedetectionoflanduseandlandcoverinanurban
regionwithSPOT-5imagesandpartialLanczosextremelearningmachine. J.Appl. RemoteSens. 2010,
4,43551. [CrossRef]
76. Nemmour,H.;Chibani,Y.NeuralNetworkCombinationbyFuzzyIntegralforRobustChangeDetectionin
RemotelySensedImagery. EURASIPJ.Adv. SignalProcess. 2005,2005,2187–2195. [CrossRef]
77. Nemmour, H.; Chibani, Y. Fuzzy neural network architecture for change detection in remotely sensed
imagery. Int. J.RemoteSens. 2006,27,705–717. [CrossRef]
78. Peng,D.;Guan,H.Unsupervisedchangedetectionmethodbasedonsaliencyanalysisandconvolutional
neuralnetwork. J.Appl. RemoteSens. 2019,13,024512. [CrossRef]
79. Zhang,P.;Gong,M.;Zhang,H.;Liu,J.;Ban,Y.UnsupervisedDifferenceRepresentationLearningforDetecting
MultipleTypesofChangesinMultitemporalRemoteSensingImages. IEEETrans. Geosci. RemoteSens.2018,
57,2277–2289. [CrossRef]
80. Fan,J.;Lin,K.;Han,M.ANovelJointChangeDetectionApproachBasedonWeight-ClusteringSparse
Autoencoders. IEEEJ.Sel. Top. Appl. EarthObs. RemoteSens. 2019,12,685–699. [CrossRef]
81. Bai,T.;Sun,K.;Deng,S.;Chen,Y.Comparisonoffourmachinelearningmethodsforobject-orientedchange
detectioninhigh-resolutionsatelliteimagery. InMippr2017: RemoteSensingImageProcessing,Geographic
InformationSystems,andOtherApplications;Sang,N.,Ma,J.,Chen,Z.,Eds.;Spie-IntSocOpticalEngineering:
Bellingham,WA,USA,2018;Volume10611.
82. Saha,S.;Bovolo,F.;Bruzzone,L.Unsupervisedmultiple-changedetectioninVHRopticalimagesusing
deepfeatures. InProceedingsofthe2018IEEEInternationalGeoscienceandRemoteSensingSymposium,
Valencia,Spain,22–27July2018;IEEE:NewYork,NY,USA,2018;pp.1902–1905.
83. Gong,M.;Yang,Y.;Zhan,T.;Niu,X.;Liu,C.AGenerativeDiscriminatoryClassifiedNetworkforChange
Detection in Multispectral Imagery. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2019, 12, 321–333.
[CrossRef]
84. Gong,M.;Zhan,T.;Zhang,P.;Miao,Q.Superpixel-BasedDifferenceRepresentationLearningforChange
DetectioninMultispectralRemoteSensingImages. IEEETrans. Geosci. Remote. Sens. 2017,55,2658–2673.
[CrossRef]
85. Huang,F.;Yu,Y.;Feng,T.Automaticbuildingchangeimagequalityassessmentinhighresolutionremote
sensingbasedondeeplearning. J.Vis. Commun. ImageRepresent. 2019,63,10. [CrossRef]
86. Nemoto,K.; Imaizumi,T.; Hikosaka,S.; Hamaguchi,R.; Sato,M.; Fujita, A.Buildingchangedetection
viaacombinationofCNNsusingonlyRGBaerialimageries. RemoteSens. Technol. Appl. UrbanEnviron.
2017,10431. [CrossRef]
87. Han,P.;Ma,C.;Li,Q.;Leng,P.;Bu,S.;Li,K.Aerialimagechangedetectionusingdualregionsofinterest
networks. Neurocomputing2019,349,190–201. [CrossRef]
88. Ji,S.;Wei,S.;Lu,M.FullyConvolutionalNetworksforMultisourceBuildingExtractionfromanOpenAerial
andSatelliteImageryDataSet. IEEETrans. Geosci. RemoteSens. 2018,57,574–586. [CrossRef]
89. Ji,S.;Shen,Y.;Lu,M.;Zhang,Y.BuildingInstanceChangeDetectionfromLarge-ScaleAerialImagesusing
ConvolutionalNeuralNetworksandSimulatedSamples. RemoteSens. 2019,11,1343. [CrossRef]
90. Sun,B.;Li,G.-Z.;Han,M.;Lin,Q.-H.Adeeplearningapproachtodetectingchangesinbuildingsfromaerial
images. InProceedingsoftheInternationalSymposiumonNeuralNetworks,Moscow,Russia,10–12July
2019;pp.414–421.
RemoteSens.2020,12,1688 28of35
91. Zhang,Z.;Vosselman,G.;Gerke,M.;Persello,C.;Tuia,D.;Yang,M.Y.DetectingBuildingChangesbetween
AirborneLaserScanningandPhotogrammetricData. RemoteSens. 2019,11,2417. [CrossRef]
92. Fujita,A.;Sakurada,K.;Imaizumi,T.;Ito,R.;Hikosaka,S.;Nakamura,R.Damagedetectionfromaerialimages
viaconvolutionalneuralnetworks. InProceedingsofthe2017FifteenthIAPRInternationalConferenceon
MachineVisionApplications(MVA),NagoyaUniv,Nagoya,Japan,08–12May2017;pp.5–8.
93. Fang,B.;Chen,G.;Pan,L.;Kou,R.;Wang,L.GAN-BasedSiameseFrameworkforLandslideInventory
MappingUsingBi-TemporalOpticalRemoteSensingImages. IEEEGeosci. RemoteSens. Lett. 2020,1–5.
[CrossRef]
94. Jiang, H.; Hu, X.; Li, K.; Zhang, J.; Gong, J.; Zhang, M. PGA-SiamNet: Pyramid Feature-Based
Attention-GuidedSiameseNetworkforRemoteSensingOrthoimageryBuildingChangeDetection. Remote
Sens. 2020,12,484. [CrossRef]
95. Wiratama,W.;Sim,D.FusionNetworkforChangeDetectionofHigh-ResolutionPanchromaticImagery.
Appl. Sci. 2019,9,1441. [CrossRef]
96. Chan,Y.K.;Koo,V.C.Anintroductiontosyntheticapertureradar(SAR).Prog. Electromagn. Res. B2008,
2,27–60. [CrossRef]
97. De,S.;Pirrone,D.;Bovolo,F.;Bruzzone,L.;Bhattacharya,A.Anovelchangedetectionframeworkbased
ondeeplearningfortheanalysisofmulti-temporalpolarimetricSARimages. InProceedingsofthe2017
IEEEInternationalGeoscienceandRemoteSensingSymposium,FortWorth,TX,USA,23–28July2017;IEEE:
NewYork,NY,USA,2017;pp.5193–5196.
98. Chen,H.;Jiao,L.;Liang,M.;Liu,F.;Yang,S.;Hou,B.Fastunsuperviseddeepfusionnetworkforchange
detectionofmultitemporalSARimages. Neurocomputing2019,332,56–70. [CrossRef]
99. Geng,J.;Wang,H.Y.;Fan,J.C.;Ma,X.R.ChangeDetectionofSARImagesBasedonSupervisedContractive
AutoencodersandFuzzyClustering. InProceedingsoftheInternationalWorkshoponRemoteSensingwith
IntelligentProcessing(RSIP),ShangHai,China,18–21May2017;IEEE:NewYork,NY,USA,2017.
100. Gong,M.;Yang,H.;Zhang,P.Featurelearningandchangefeatureclassificationbasedondeeplearningfor
ternarychangedetectioninSARimages. ISPRSJ.Photogramm. RemoteSens. 2017,129,212–225. [CrossRef]
101. Lei,Y.;Liu,X.;Shi,J.;Lei,C.;Wang,J.MultiscaleSuperpixelSegmentationwithDeepFeaturesforChange
Detection. IEEEAccess2019,7,36600–36616. [CrossRef]
102. Li,Y.Y.;Zhou,L.H.;Peng,C.;Jiao,L.C.Spatialfuzzyclusteringanddeepauto-encoderforunsupervised
change detection in synthetic aperture radar images. In Proceedings of the 2018 IEEE International
GeoscienceandRemoteSensingSymposium,Valencia,Spain,22–27July2018;IEEE:NewYork,NY,USA,
2018;pp.4479–4482.
103. Lv, N.; Chen, C.; Qiu, T.; Sangaiah, A.K. Deep Learning and Superpixel Feature Extraction Based on
ContractiveAutoencoderforChangeDetectioninSARImages. IEEETrans. Ind. Inform. 2018,14,5530–5538.
[CrossRef]
104. Planinšicˇ,P.; Gleich,D.TemporalChangeDetectioninSARImagesUsingLogCumulantsandStacked
Autoencoder. IEEEGeosci. RemoteSens. Lett. 2018,15,297–301. [CrossRef]
105. Su,L.;Cao,X.Fuzzyautoencoderformultiplechangedetectioninremotesensingimages.J.Appl.RemoteSens.
2018,12,035014. [CrossRef]
106. Su,L.Z.;Shi,J.;Zhang,P.Z.;Wang,Z.;Gong,M.G.Detectingmultiplechangesfrommulti-temporalimagesby
usingstackeddenosingautoencoderbasedchangevectoranalysis. InProceedingsofthe2016International
JointConferenceonNeuralNetworks,Vancouver,Canada,24–29July2016;IEEE:NewYork,NY,USA,2016;
pp.1269–1276.
107. Luo,B.;Hu,C.;Su,X.;Wang,Y.DifferentiallyDeepSubspaceRepresentationforUnsupervisedChange
DetectionofSARImages. RemoteSens. 2019,11,2740. [CrossRef]
108. Dong,H.;Ma,W.;Wu,Y.;Gong,M.;Jiao,L.LocalDescriptorLearningforChangeDetectioninSynthetic
ApertureRadarImagesviaConvolutionalNeuralNetworks. IEEEAccess2018,7,15389–15403. [CrossRef]
109. Liu,T.;Li,Y.;Cao,Y.;Shen,Q.Changedetectioninmultitemporalsyntheticapertureradarimagesusing
dual-channelconvolutionalneuralnetwork. J.Appl. RemoteSens. 2017,11,1. [CrossRef]
110. Saha,S.;Bovolo,F.;Bruzzone,L.Destroyed-buildingsdetectionfromVHRSARimagesusingdeepfeatures.
InImageandSignalProcessingforRemoteSensingaXxiv;Bruzzone,L.,Bovolo,F.,Eds.;Spie-IntSocOptical
Engineering: Bellingham,WA,USA,2018;Volume10789.
RemoteSens.2020,12,1688 29of35
111. Li,Y.;Peng,C.;Chen,Y.;Jiao,L.;Zhou,L.;Shang,R.ADeepLearningMethodforChangeDetectionin
SyntheticApertureRadarImages. IEEETrans. Geosci. RemoteSens. 2019,57,5751–5763. [CrossRef]
112. Jaturapitpornchai, R.; Matsuoka, M.; Kanemoto, N.; Kuzuoka, S.; Ito, R.; Nakamura, R. Newly Built
ConstructionDetectioninSARImagesUsingDeepLearning. RemoteSens. 2019,11,1444. [CrossRef]
113. Cui,B.; Zhang,Y.; Yan,L.; Wei,J.; Wu,H.AnUnsupervisedSARChangeDetectionMethodBasedon
StochasticSubspaceEnsembleLearning. RemoteSens. 2019,11,1314. [CrossRef]
114. Liu,F.;Jiao,L.;Tang,X.;Yang,S.;Ma,W.;Hou,B.LocalRestrictedConvolutionalNeuralNetworkforChange
DetectioninPolarimetricSARImages. IEEETrans. NeuralNetw. Learn. Syst. 2019,30,818–833. [CrossRef]
115. Guo,E.;Fu,X.;Zhu,J.;Deng,M.;Liu,Y.;Zhu,Q.;Li,H.Learningtomeasurechange: Fullyconvolutional
Siamesemetricnetworksforscenechangedetection. arXiv2018,arXiv:1810.09111.
116. Huélamo,C.G.;Alcantarilla,P.F.;Bergasa,L.M.;López-Guillén,E.ChangedetectiontoolbasedonGSVto
helpDNNstraining. InProceedingsoftheWorkshopofPhysicalAgents,Madrid,Spain,22–23November
2018;pp.115–131.
117. Varghese,A.;Gubbi,J.;Ramaswamy,A.;Balamuralidhar,P.ChangeNet: Adeeplearningarchitecturefor
visualchangedetection. InProceedingsoftheEuropeanConferenceonComputerVision(ECCV),Munich,
Germany,8–14September2018;pp.129–145.
118. Sakurada,K.;Wang,W.;Kawaguchi,N.;Nakamura,R.Denseopticalflowbasedchangedetectionnetwork
robusttodifferenceofcameraviewpoints. arXiv2017,arXiv:1712.02941.
119. Sakurada,K.;Okatani,T.ChangedetectionfromastreetimagepairusingCNNfeaturesandsuperpixel
segmentation. In Proceedings of the British Machine Vision Conference (BMVC), Swansea, UK, 7–10
September2015;pp.61.1–61.12.
120. Bu, S.; Li, Q.; Han, P.; Leng, P.; Li, K. Mask-CDNet: A mask based pixel change detection network.
Neurocomputing2020,378,166–178. [CrossRef]
121. Liu,J.;Gong,M.;Qin,A.;Zhang,P.ADeepConvolutionalCouplingNetworkforChangeDetectionBased
onHeterogeneousOpticalandRadarImages. IEEETrans. NeuralNetw. Learn. Syst. 2018,29,545–559.
[CrossRef]
122. Zhan,T.;Gong,M.;Jiang,X.;Li,S.Log-BasedTransformationFeatureLearningforChangeDetectionin
HeterogeneousImages. IEEEGeosci. RemoteSens. Lett. 2018,15,1352–1356. [CrossRef]
123. Zhan,T.;Gong,M.;Liu,J.;Zhang,P.Iterativefeaturemappingnetworkfordetectingmultiplechangesin
multi-sourceremotesensingimages. ISPRSJ.Photogramm. RemoteSens. 2018,146,38–51. [CrossRef]
124. Ma,W.;Xiong,Y.;Wu,Y.;Yang,H.;Zhang,X.-R.;Jiao,L.ChangeDetectioninRemoteSensingImagesBased
onImageMappingandaDeepCapsuleNetwork. RemoteSens. 2019,11,626. [CrossRef]
125. Yang,M.;Jiao,L.;Liu,F.;Hou,B.;Yang,S.TransferredDeepLearning-BasedChangeDetectioninRemote
SensingImages. IEEETrans. Geosci. RemoteSens. 2019,57,6960–6973. [CrossRef]
126. Gong,M.;Niu,X.;Zhan,T.;Zhang,M.Acouplingtranslationnetworkforchangedetectioninheterogeneous
images. Int. J.RemoteSens. 2018,40,3647–3672. [CrossRef]
127. Niu, X.; Gong, M.; Zhan, T.; Yang, Y. A Conditional Adversarial Network for Change Detection in
HeterogeneousImages. IEEEGeosci. RemoteSens. Lett. 2018,16,45–49. [CrossRef]
128. Zhang,C.;Wei,S.;Ji,S.;Lu,M.DetectingLarge-ScaleUrbanLandCoverChangesfromVeryHighResolution
RemoteSensingImagesUsingCNN-BasedClassification. ISPRSInt. J.GeoInf. 2019,8,189. [CrossRef]
129. Chen,Z.;Zhang,Y.;Ouyang,C.;Zhang,F.;Ma,J.AutomatedLandslidesDetectionforMountainCities
UsingMulti-TemporalRemoteSensingImagery. Sensors2018,18,821. [CrossRef]
130. Huang,D.M.;Wei,C.T.;Yu,J.C.;Wang,J.L.Amethodofdetectinglandusechangeofremotesensingimages
basedontexturefeaturesandDEM.InProceedingsoftheInternationalConferenceonIntelligentEarth
ObservingandApplications, Guilin, China, 23–24October2015; Zhou,G., Kang,C., Eds.; Spie-IntSoc
OpticalEngineering: Bellingham,WA,USA,2015;Volume9808.
131. Iino,S.;Ito,R.;Doi,K.;Imaizumi,T.;Hikosaka,S.CNN-basedgenerationofhigh-accuracyurbandistribution
maps utilising SAR satellite imagery for short-term change monitoring. Int. J. Image Data Fusion 2018,
9,302–318. [CrossRef]
132. Goyette,N.;Jodoin,P.-M.;Porikli,F.;Konrad,J.;Ishwar,P.Changedetection. net: Anewchangedetection
benchmarkdataset. InProceedingsofthe2012IEEEComputerSocietyConferenceonComputerVisionand
PatternRecognitionWorkshops,Providence,RI,USA,16–21June2012;pp.1–8.
RemoteSens.2020,12,1688 30of35
133. Wang,Y.;Jodoin,P.-M.;Porikli,F.;Konrad,J.;Benezeth,Y.;Ishwar,P.CDnet2014: AnExpandedChange
DetectionBenchmarkDataset. InProceedingsofthe2014IEEEConferenceonComputerVisionandPattern
RecognitionWorkshops,Columbus,OH,USA,23–28June2014;pp.393–400.
134. Goyette,N.;Jodoin,P.-M.;Porikli,F.;Konrad,J.;Ishwar,P.ANovelVideoDatasetforChangeDetection
Benchmarking. IEEETrans. ImageProcess. 2014,23,4663–4679. [CrossRef]
135. Hyperspectral Change Detection Dataset. Available online: https://citius.usc.es/investigacion/datasets/
hyperspectral-change-detection-dataset(accessedon4May2020).
136. Daudt,R.C.;LeSaux,B.;Boulch,A.;Gousseau,Y.Multitasklearningforlarge-scalesemanticchangedetection.
Comput. Vis. ImageUnderst. 2019,187,102783. [CrossRef]
137. Benedek,C.;Sziranyi,T.ChangeDetectioninOpticalAerialImagesbyaMultilayerConditionalMixed
MarkovModel. IEEETrans. Geosci. RemoteSens. 2009,47,3416–3430. [CrossRef]
138. Benedek,C.; Sziranyi,T.AMixedMarkovmodelforchangedetectioninaerialphotoswithlargetime
differences. InProceedingsofthe200819thInternationalConferenceonPatternRecognition,Tampa,FL,
USA,8–11December2008;pp.1–4.
139. Daudt,R.C.;LeSaux,B.;Boulch,A.;Gousseau,Y.Urbanchangedetectionformultispectralearthobservation
usingconvolutionalneuralnetworks. InProceedingsoftheIGARSS2018IEEEInternationalGeoscienceand
RemoteSensingSymposium,Valencia,Spain,22–27July2018;pp.2115–2118.
140. Zhang,M.;Shi,W.AFeatureDifferenceConvolutionalNeuralNetwork-BasedChangeDetectionMethod.
IEEETrans. Geosci. RemoteSens. 2020,1–15. [CrossRef]
141. Wu,C.;Zhang,L.;Zhang,L.Ascenechangedetectionframeworkformulti-temporalveryhighresolution
remotesensingimages. SignalProcess. 2016,124,184–197. [CrossRef]
142. Gupta,R.;Goodman,B.;Patel,N.;Hosfelt,R.;Sajeev,S.;Heim,E.;Doshi,J.;Lucas,K.;Choset,H.;Gaston,M.
CreatingxBD:Adatasetforassessingbuildingdamagefromsatelliteimagery. InProceedingsoftheIEEE
ConferenceonComputerVisionandPatternRecognitionWorkshops,LongBeach,CA,USA,16–20June
2019;pp.10–17.
143. Bourdis,N.;Marraud,D.;Sahbi,H.Constrainedopticalflowforaerialimagechangedetection.InProceedings
ofthe2011IEEEInternationalGeoscienceandRemoteSensingSymposium,Vancouver,BC,Canada,24–29
July2011;pp.4176–4179. [CrossRef]
144. Lebedev,M.A.;Vizilter,Y.V.;Vygolov,O.V.;Knyaz,V.A.;Rubis,A.Y.Changedetectioninremotesensing
imagesusingconditionaladversarialnetworks. ISPRSInt. Arch. Photogramm. RemoteSens. Spat. Inf. Sci.
2018,565–571. [CrossRef]
145. Alcantarilla,P.F.;Stent,S.;Ros,G.;Arroyo,R.;Gherardi,R.Street-viewchangedetectionwithdeconvolutional
networks. Auton. Robot. 2018,42,1301–1322. [CrossRef]
146. Sakurada,K.;Okatani,T.;Deguchi,K.Detectingchangesin3Dstructureofascenefrommulti-viewimages
capturedbyavehicle-mountedcamera. InProceedingsoftheIEEEConferenceonComputerVisionand
PatternRecognition,Portland,OR,USA,23–28June2013;pp.137–144.
147. Zagoruyko, S.; Komodakis, N. Learning to compare image patches via convolutional neural networks.
InProceedingsofthe2015IEEEConferenceonComputerVisionandPatternRecognition,Boston,MA,USA,
7–12June2015;IEEE:NewYork,NY,USA,2015;pp.4353–4361.
148. Liu,J.;Gong,M.;Zhao,J.;Li,H.;Jiao,L.DifferencerepresentationlearningusingstackedrestrictedBoltzmann
machinesforchangedetectioninSARimages. SoftComput. 2014,20,4645–4657. [CrossRef]
149. Aghababaee,H.;Amini,J.;Tzeng,Y.ImprovingchangedetectionmethodsofSARimagesusingfractals.
Sci. Iran.2013,20,15–22. [CrossRef]
150. Gopal,S.;Woodcock,C.Remotesensingofforestchangeusingartificialneuralnetworks. IEEETrans. Geosci.
RemoteSens. 1996,34,398–404. [CrossRef]
151. Xu,J.;Zhang,B.;Guo,H.;Lu,J.;Lin,Y.Combiningiterativeslowfeatureanalysisanddeepfeaturelearning
for change detection in high-resolution remote sensing images. J. Appl. Remote Sens. 2019, 13, 024506.
[CrossRef]
152. Touazi,A.;Bouchaffra,D.Ak-nearestneighborapproachtoimprovechangedetectionfromremotesensing:
Applicationtoopticalaerialimages. InProceedingsofthe201515thInternationalConferenceonIntelligent
SystemsDesignandApplications,Marrakech,Morocco,14–16December2015;Abraham,A.,Alimi,A.M.,
Haqiq,A.,Barbosa,L.O.,BenAmar,C.,Berqia,A.,BenHalima,M.,Muda,A.M.,Ma,K.,Eds.;IEEE:NewYork,
NY,USA,2015;pp.98–103.
RemoteSens.2020,12,1688 31of35
153. Gao,Y.; Gao,F.; Dong,J.; Wang,S.ChangeDetectionfromSyntheticApertureRadarImagesBasedon
ChannelWeighting-BasedDeepCascadeNetwork. IEEEJ.Sel. Top. Appl. EarthObs. RemoteSens. 2019,
12,4517–4529. [CrossRef]
154. Keshk,H.;Yin,X.-C.ChangeDetectioninSARImagesBasedonDeepLearning. Int. J.Aeronaut. SpaceSci.
2019,1–11. [CrossRef]
155. Zhang,M.;Xu,G.;Chen,K.;Yan,M.;Sun,X.Triplet-BasedSemanticRelationLearningforAerialRemote
SensingImageChangeDetection. IEEEGeosci. RemoteSens. Lett. 2018,16,266–270. [CrossRef]
156. Hedjam,R.;Abdesselam,A.;Melgani,F.Changedetectionfromunlabeledremotesensingimagesusing
siameseANN.InProceedingsoftheIGARSS2019—2019IEEEInternationalGeoscienceandRemoteSensing
Symposium,Yokohama,Japan,28July–2August2019;pp.1530–1533.
157. Chu,Y.;Cao,G.;Hayat,H.Changedetectionofremotesensingimagebasedondeepneuralnetworks. In
Proceedingsofthe20162ndInternationalConferenceonArtificialIntelligenceandIndustrialEngineering,
Beijing,China,20–11November2016;Sehiemy,R.E.,Reaz,M.B.I.,Eds.;AtlantisPress: Paris,France,2016;
Volume133,pp.262–267.
158. Wiratama, W.; Lee, J.; Park, S.-E.; Sim, D. Dual-Dense Convolution Network for Change Detection of
High-ResolutionPanchromaticImagery. Appl. Sci. 2018,8,1785. [CrossRef]
159. Nguyen,T.P.;Pham,C.C.;Ha,S.V.-U.;Jeon,J.W.ChangeDetectionbyTrainingaTripletNetworkforMotion
FeatureExtraction. IEEETrans. CircuitsSyst. VideoTechnol. 2018,29,433–446. [CrossRef]
160. Su,L.;Gong,M.;Zhang,P.;Zhang,M.;Liu,J.;Yang,H.Deeplearningandmappingbasedternarychange
detectionforinformationunbalancedimages. PatternRecognit. 2017,66,213–228. [CrossRef]
161. Ye,Q.;Lu,X.;Huo,H.;Wan,L.;Guo,Y.;Fang,T.AggregationNet: Identifyingmultiplechangesbasedon
convolutionalneuralnetworkinbitemporalopticalremotesensingimages. InProceedingsofthePacific-Asia
ConferenceonKnowledgeDiscoveryandDataMining,Macau,China,14–17April2019;pp.375–386.
162. Du, B.; Ru, L.; Wu, C.; Zhang, L. Unsupervised Deep Slow Feature Analysis for Change Detection in
Multi-TemporalRemoteSensingImages. IEEETrans. Geosci. RemoteSens. 2019,57,9976–9992. [CrossRef]
163. Wu,C.;Chen,H.;Do,B.;Zhang,L.Unsupervisedchangedetectioninmulti-temporalVHRimagesbasedon
deepkernelPCAconvolutionalmappingnetwork. arXiv2019,arXiv:1912.08628.
164. Rahman,F.; Vasu,B.; VanCor,J.; Kerekes,J.; Savakis,A.Siamesenetworkwithmulti-levelfeaturesfor
patch-basedchangedetectioninsatelliteimagery. InProceedingsofthe2018IEEEGlobalConferenceon
SignalandInformationProcessing,Anaheim,CA,USA,26–29November2018;IEEE:NewYork,NY,USA,
2018;pp.958–962.
165. Chen,H.;Wu,C.;Du,B.;Zhang,L.Deepsiamesemulti-scaleconvolutionalnetworkforchangedetectionin
multi-temporalVHRimages. InProceedingsofthe201910thInternationalWorkshopontheAnalysisof
MultitemporalRemoteSensingImages(MultiTemp),Shanghai,China,5–7August2019;pp.1–4.
166. Wang,M.;Tan,K.;Jia,X.;Wang,X.;Chen,Y.ADeepSiameseNetworkwithHybridConvolutionalFeature
ExtractionModuleforChangeDetectionBasedonMulti-sensorRemoteSensingImages. RemoteSens. 2020,
12,205. [CrossRef]
167. Lim, K.; Jin, D.; Kim, C.-S. Change detection in high resolution satellite images using an ensemble of
convolutionalneuralnetworks. InProceedingsofthe2018Asia-PacificSignalandInformationProcessing
AssociationAnnualSummitandConference(APSIPAASC),Honolulu,HI,USA,12–15November2018;
pp.509–515.
168. ElAmin,A.M.;Liu,Q.;Wang,Y.ZoomoutCNNsFeaturesforOpticalRemoteSensingChangeDetection. In
Proceedingsofthe20172ndInternationalConferenceonImage,VisionandComputing(ICIVC),Chengdu,
China,2–4June2017;pp.812–817.
169. Liu,J.;Chen,K.;Xu,G.;Sun,X.;Yan,M.;Diao,W.;Han,H.ConvolutionalNeuralNetwork-BasedTransfer
LearningforOpticalAerialImagesChangeDetection. IEEEGeosci. RemoteSens. Lett. 2020,17,127–131.
[CrossRef]
170. Kerner,H.R.;Wagstaff,K.L.;Bue,B.D.;Gray,P.C.;Bell,J.F.;BenAmor,H.;Iii,J.F.B.TowardGeneralized
ChangeDetectiononPlanetarySurfaceswithConvolutionalAutoencodersandTransferLearning. IEEEJ.
Sel. Top. Appl. EarthObs. RemoteSens. 2019,12,3900–3918. [CrossRef]
171. Gao, Y.; Gao, F.; Dong, J.; Wang, S. Transferred Deep Learning for Sea Ice Change Detection from
Synthetic-ApertureRadarImages. IEEEGeosci. RemoteSens. Lett. 2019,16,1655–1659. [CrossRef]
RemoteSens.2020,12,1688 32of35
172. Wang,Y.;Du,B.;Ru,L.;Wu,C.;Luo,H.Scenechangedetectionviadeepconvolutioncanonicalcorrelation
analysisneuralnetwork. InProceedingsoftheIGARSS2019—2019IEEEInternationalGeoscienceand
RemoteSensingSymposium,Yokohama,Japan,28July–2August2019;pp.198–201.
173. Hou,B.;Wang,Y.;Liu,Q.ChangeDetectionBasedonDeepFeaturesandLowRank. IEEEGeosci. Remote
Sens. Lett. 2017,14,2418–2422. [CrossRef]
174. ElAmin,A.M.;Liu,Q.;Wang,Y.Convolutionalneuralnetworkfeaturesbasedchangedetectioninsatellite
images. InFroceedingsoftheFirstInternationalWorkshoponPatternRecognition,Tokyo,Japan,11–13May2016;
Jiang,X.,Chen,G.,Capi,G.,Ishii,C.,Eds.;Spie-IntSocOpticalEngineering: Bellingham,WA,USA,2016;
Volume0011.
175. Cao,C.;Dragic´evic´,S.;Li,S.Land-UseChangeDetectionwithConvolutionalNeuralNetworkMethods.
Environments2019,6,25. [CrossRef]
176. Wu,C.;Zhang,L.;Du,B.KernelSlowFeatureAnalysisforSceneChangeDetection. IEEETrans. Geosci.
RemoteSens. 2017,55,2367–2384. [CrossRef]
177. Ghaffarian,S.;Kerle,N.;Pasolli,E.;Arsanjani,J.J.Post-DisasterBuildingDatabaseUpdatingUsingAutomated
DeepLearning: AnIntegrationofPre-DisasterOpenStreetMapandMulti-TemporalSatelliteData. Remote
Sens. 2019,11,2427. [CrossRef]
178. Gao,F.;Dong,J.;Li,B.;Xu,Q.AutomaticChangeDetectioninSyntheticApertureRadarImagesBasedon
PCANet. IEEEGeosci. RemoteSens. Lett. 2016,13,1–5. [CrossRef]
179. Gao,F.;Liu,X.;Dong,J.;Zhong,G.;Jian,M.ChangeDetectioninSARImagesBasedonDeepSemi-NMF
andSVDNetworks. RemoteSens. 2017,9,435. [CrossRef]
180. Li,M.;Lia,M.;Zhang,P.;Wu,Y.;Song,W.;An,L.SARImageChangeDetectionUsingPCANetGuidedby
SaliencyDetection. IEEEGeosci. RemoteSens. Lett. 2018,16,402–406. [CrossRef]
181. Liao,F.;Koshelev,E.;Milton,M.;Jin,Y.;Lu,E.Changedetectionbydeepneuralnetworksforsynthetic
apertureradarimages. InProceedingsofthe2017InternationalConferenceonComputing,Networkingand
Communications(ICNC),SantaClara,CA,USA,26–29January2017;pp.947–951.
182. Zhao,Q.N.;Gong,M.G.;Li,H.;Zhan,T.;Wang,Q.Three-classchangedetectioninsyntheticapertureradar
imagesbasedondeepbeliefnetwork. InBio-InspiredComputing—TheoriesandApplications, Bic-Ta2015;
Gong,M.,Pan,L.,Song,T.,Tang,K.,Zhang,X.,Eds.;Springer: Berlin/Heidelberg,Germany,2015;Volume
562,pp.696–705.
183. Samadi,F.;Akbarizadeh,G.;Kaabi,H.ChangedetectioninSARimagesusingdeepbeliefnetwork: Anew
trainingapproachbasedonmorphologicalimages. IETImageProcess. 2019,13,2255–2264. [CrossRef]
184. Zhao,W.;Wang,Z.;Gong,M.;Liu,J.DiscriminativeFeatureLearningforUnsupervisedChangeDetection
inHeterogeneousImagesBasedonaCoupledNeuralNetwork. IEEETrans. Geosci. RemoteSens. 2017,
55,7066–7080. [CrossRef]
185. Daudt,R.C.;Saux,B.L.;Boulch,A.;Gousseau,Y.Guidedanisotropicdiffusionanditerativelearningfor
weaklysupervisedchangedetection. arXiv2019,arXiv:1904.08208.
186. Connors,C.; Vatsavai,R.R.Semi-superviseddeepgenerativemodelsforchangedetectioninveryhigh
resolutionimagery.InProceedingsofthe2017IEEEInternationalGeoscienceandRemoteSensingSymposium,
FortWorth,TX,USA,23–28July2017;pp.1063–1066.
187. Li,H.-C.;Yang,G.;Yang,W.;Du,Q.;Emery,W.J.Deepnonsmoothnonnegativematrixfactorizationnetwork
withsemi-supervisedlearningforSARimagechangedetection. ISPRSJ.Photogramm. RemoteSens. 2020,
160,167–179. [CrossRef]
188. Zhang,X.;Shi,W.;Lv,Z.;Peng,F.LandCoverChangeDetectionfromHigh-ResolutionRemoteSensing
ImageryUsingMultitemporalDeepFeatureCollaborativeLearningandaSemi-supervisedChan–Vese
Model. RemoteSens. 2019,11,2787. [CrossRef]
189. Liu,G.;Li,L.;Jiao,L.;Dong,Y.;Li,X.StackedFisherautoencoderforSARchangedetection. PatternRecognit.
2019,96,106971. [CrossRef]
190. Sublime,J.;Kalinicheva,E.AutomaticPost-DisasterDamageMappingUsingDeep-LearningTechniquesfor
ChangeDetection: CaseStudyoftheTohokuTsunami. RemoteSens. 2019,11,1123. [CrossRef]
191. Goodfellow,I.;Bengio,Y.;Courville,A.DeepLearning;MITPress: Cambridge,MA,USA,2016.
192. Zhu,B.;Gao,H.;Wang,X.;Xu,M.;Zhu,X.ChangeDetectionBasedontheCombinationofImprovedSegNet
NeuralNetworkandMorphology. InProceedingsofthe2018IEEE3rdInternationalConferenceonImage,
VisionandComputing(ICIVC),ChongQing,China,27–29June2018;pp.55–59.
RemoteSens.2020,12,1688 33of35
193. Peng,D.;Zhang,Y.;Guan,H.GuanEnd-to-EndChangeDetectionforHighResolutionSatelliteImages
UsingImprovedUNet++. RemoteSens. 2019,11,1382. [CrossRef]
194. Venugopal,N.AutomaticSemanticSegmentationwithDeepLabDilatedLearningNetworkforChange
DetectioninRemoteSensingImages. NeuralProcess. Lett. 2020,1–23. [CrossRef]
195. Venugopal,N.SampleSelectionBasedChangeDetectionwithDilatedNetworkLearninginRemoteSensing
Images. Sens. Imaging: Int. J.2019,20,31. [CrossRef]
196. Khan,S.;He,X.;Porikli,F.;Bennamoun,M.ForestChangeDetectioninIncompleteSatelliteImageswith
DeepNeuralNetworks. IEEETrans. Geosci. RemoteSens. 2017,55,5407–5423. [CrossRef]
197. Wang,Q.; Zhang,X.; Chen,G.; Dai,F.; Gong,Y.; Zhu,K.ChangedetectionbasedonFasterR-CNNfor
high-resolutionremotesensingimages. RemoteSens. Lett. 2018,9,923–932. [CrossRef]
198. Dewan,N.;Kashyap,V.;Kushwaha,A.S.Areviewofpulsecoupledneuralnetwork. IioabJ.2019,10,61–65.
199. Liu,R.;Jia,Z.;Qin,X.;Yang,J.;Kasabov,N.K.SARImageChangeDetectionMethodBasedonPulse-Coupled
NeuralNetwork. J.IndianSoc. RemoteSens. 2016,44,443–450. [CrossRef]
200. Pratola,C.;DelFrate,F.;Schiavon,G.;Solimini,D.TowardFullyAutomaticDetectionofChangesinSuburban
AreasfromVHRSARImagesbyCombiningMultipleNeural-NetworkModels. IEEETrans. Geosci. Remote
Sens. 2013,51,2055–2066. [CrossRef]
201. Zhong,Y.;Liu,W.;Zhao,J.;Zhang,L.ChangeDetectionBasedonPulse-CoupledNeuralNetworksandthe
NMIFeatureforHighSpatialResolutionRemoteSensingImagery. IEEEGeosci. RemoteSens. Lett. 2015,
12,537–541. [CrossRef]
202. Goodfellow,I.J.;Pouget-Abadie,J.;Mirza,M.;Xu,B.;Warde-Farley,D.;Ozair,S.;Courville,A.;Bengio,Y.
Generative adversarial nets. In Advances in Neural Information Processing Systems 27; Ghahramani, Z.,
Welling,M.,Cortes,C.,Lawrence,N.D.,Weinberger,K.Q.,Eds.;NIPS:LaJolla,CA,USA,2014;Volume27.
203. Gong,M.;Niu,X.;Zhang,P.;Li,Z.GenerativeAdversarialNetworksforChangeDetectioninMultispectral
Imagery. IEEEGeosci. Remote. Sens. Lett. 2017,14,2310–2314. [CrossRef]
204. Hou, B.; Liu, Q.; Wang, H.; Wang, Y. From W-Net to CDGAN: BitemporalChange Detection via Deep
LearningTechniques. IEEETrans. Geosci. RemoteSens. 2020,58,1790–1802. [CrossRef]
205. Wang,Q.;Shi,W.;Atkinson,P.;Li,Z.LandCoverChangeDetectionatSubpixelResolutionwithaHopfield
NeuralNetwork. IEEEJ.Sel. Top. Appl. EarthObs. RemoteSens. 2014,8,1–14. [CrossRef]
206. Chen,K.;Huo,C.;Zhou,Z.;Lu,H.UnsupervisedChangeDetectioninHighSpatialResolutionOpticalImagery
BasedonModifiedHopfieldNeuralNetwork;IEEE:NewYork,NY,USA,2008;pp.281–285. [CrossRef]
207. Subudhi,B.N.;Ghosh,S.;Ghosh,A.Spatialconstrainthopfield-typeneuralnetworksfordetectingchanges
inremotelysensedmultitemporalimages. InProceedingsofthe201320thIEEEInternationalConferenceon
ImageProcessing,Melbourne,VIC,Australia,15–18September2013;pp.3815–3819.
208. Wu,K.;Du,Q.;Wang,Y.;Yang,Y.SupervisedSub-PixelMappingforChangeDetectionfromRemotely
SensedImageswithDifferentResolutions. RemoteSens. 2017,9,284. [CrossRef]
209. Dalmiya,C.P.;Santhi,N.;Sathyabama,B.Anenhancedbackpropagationmethodforchangeanalysisof
remotesensingimageswithadaptivepreprocessing. Eur. J.RemoteSens. 2019,1–12. [CrossRef]
210. Castellana,L.;D’Addabbo,A.;Pasquariello,G.Acomposedsupervised/unsupervisedapproachtoimprove
changedetectionfromremotesensing. PatternRecognit. Lett. 2007,28,405–413. [CrossRef]
211. DelFrate,F.; Pacifici,F.; Solimini,D.MonitoringUrbanLandCoverinRome,Italy,andItsChangesby
Single-PolarizationMultitemporalSARImages. IEEEJ.Sel. Top. Appl. EarthObs. RemoteSens. 2008,1,87–97.
[CrossRef]
212. Mirici, M.E. Land use/cover change modelling in a mediterranean rural landscape using multi-layer
perceptronandmarkovchain(mlp-mc). Appl. Ecol. Environ. Res. 2018,16,467–486. [CrossRef]
213. Patra,S.;Ghosh,S.;Ghosh,A.Changedetectionofremotesensingimageswithsemi-supervisedmultilayer
perceptron. Fundam. Inform. 2008,84,429–442.
214. Tarantino,C.;Blonda,P.;Pasquariello,G.Remotesenseddataforautomaticdetectionofland-usechanges
duetohumanactivityinsupporttolandslidestudies. Nat. Hazards2006,41,245–267. [CrossRef]
215. Chen,J.;Zheng,G.;Fang,C.;Zhang,N.;Chen,J.;Wu,Z.Time-seriesprocessingoflargescaleremotesensing
datawithextremelearningmachine. Neurocomputing2014,128,199–206. [CrossRef]
RemoteSens.2020,12,1688 34of35
216. Tang,S.H.; Li,T.; Cheng,X.H. ANovelRemote SensingImage ChangeDetection AlgorithmBased on
Self-OrganizingFeatureMapNeuralNetworkModel. InProceedingsofthe2016InternationalConferenceon
CommunicationandElectronicsSystems(ICCES),Coimbatore,India,21–22October2016;IEEE:NewYork,
NY,USA,2016;pp.1033–1038.
217. Xiao,R.;Cui,R.;Lin,M.;Chen,L.;Ni,Y.;Lin,X.;Lin,X.SOMDNCD:ImageChangeDetectionBasedon
Self-OrganizingMapsandDeepNeuralNetworks. IEEEAccess2018,6,35915–35925. [CrossRef]
218. Chen,X.;Li,X.W.;Ma,J.W.UrbanChangeDetectionBasedonSelf-OrganizingFeatureMapNeuralNetwork.
InProceedingsofthe2004IEEEInternationalGeoscienceandRemoteSensingSymposium,Anchorage,AK,
USA,20–24September2004;pp.3428–3431.
219. Ghosh,S.;Roy,M.;Ghosh,A.Semi-supervisedchangedetectionusingmodifiedself-organizingfeaturemap
neuralnetwork. Appl. SoftComput. 2014,15,1–20. [CrossRef]
220. Patra, S.; Ghosh, S.; Ghosh, A. Unsupervised Change Detection in Remote-Sensing Images using
One-dimensionalSelf-OrganizingFeatureMapNeuralNetwork. InProceedingsofthe9thInternational
ConferenceonInformationTechnology(ICIT’06),Bhubaneswar,India,18–21December2006;pp.141–142.
221. Song,Y.;Yuan,X.;Xu,H.;Yang,Y.Anovelimagechangedetectionmethodbasedonenhancedgrowing
self-organizationfeaturemap. GeoinformaticsRemoteSens. DataInf. 2006,6419,641915. [CrossRef]
222. Coppin, P.; Jonckheere, I.; Nackaerts, K.; Muys, B.; Lambin, E. Review ArticleDigital change detection
methodsinecosystemmonitoring: Areview. Int. J.RemoteSens. 2004,25,1565–1596. [CrossRef]
223. Karpatne, A.; Jiang, Z.; Vatsavai, R.R.; Shekhar, S.; Kumar, V. Monitoring Land-Cover Changes:
AMachine-LearningPerspective. IEEEGeosci. RemoteSens. Mag. 2016,4,8–21. [CrossRef]
224. Tomoya,M.;Kanji,T.ChangeDetectionunderGlobalViewpointUncertainty. arXiv2017,arXiv:1703.00552.
225. Yang,G.;Li,H.-C.;Wang,W.-Y.;Yang,W.;Emery,W.J.UnsupervisedChangeDetectionBasedonaUnified
FrameworkforWeightedCollaborativeRepresentationwithRDDLandFuzzyClustering. IEEETrans. Geosci.
RemoteSens. 2019,57,8890–8903. [CrossRef]
226. Durmusoglu,Z.;Tanriover,A.Modellinglanduse/coverchangeinLakeMoganandsurroundingsusing
CA-MarkovChainAnalysis. J.Environ. Boil. 2017,38,981–989. [CrossRef]
227. Fan,F.;Wang,Y.;Wang,Z.Temporalandspatialchangedetecting(1998–2003)andpredictingoflanduse
andlandcoverinCorecorridorofPearlRiverDelta(China)byusingTMandETM+images. Environ. Monit.
Assess. 2007,137,127–147. [CrossRef]
228. Tong,X.;Zhang,X.;Liu,M.Detectionofurbansprawlusingageneticalgorithm-evolvedartificialneural
networkclassificationinremotesensing: AcasestudyinJiadingandPutuodistrictsofShanghai,China. Int.
J.RemoteSens. 2010,31,1485–1504. [CrossRef]
229. Iino,S.;Ito,R.;Doi,K.;Imaizumi,T.;Hikosaka,S.Generatinghigh-accuracyurbandistributionmapfor
short-termchangemonitoringbasedonconvolutionalneuralnetworkbyutilizingSARimagery. InEarth
ResourcesandEnvironmentalRemoteSensing/GISApplicationsVIII;Michel,U.,Schulz,K.,Nikolakopoulos,K.G.,
Civco,D.,Eds.;Spie-IntSocOpticalEngineering: Bellingham,WA,USA,2017;Volume10428.
230. Rokni, K.; Ahmad, A.; Solaimani, K.; Hazini, S. A new approach for surface water change detection:
Integration of pixel level image fusion and image classification techniques. Int. J. Appl. Earth Obs.
Geoinformation2015,34,226–234. [CrossRef]
231. Song,A.;Kim,Y.;Kim,Y.ChangeDetectionofSurfaceWaterinRemoteSensingImagesBasedonFully
ConvolutionalNetwork. J.Coast. Res. 2019,91,426–430. [CrossRef]
232. Lindquist,E.;D’Annunzio,R.AssessingGlobalForestLand-UseChangebyObject-BasedImageAnalysis.
RemoteSens. 2016,8,678. [CrossRef]
233. Ding, A.; Zhang, Q.; Zhou, X.; Dai, B. Automatic Recognition of Landslide Based on CNN and
Texture Change Detection. In Proceedings of the 2016 31st Youth Academic Annual Conference of
Chinese-Association-of-Automation(YAC),Wuhan,China,11–13November2016;pp.444–448.
234. Singh, A.; Singh, K.K.; Nigam, M.J.; Pal, K. Detection of tsunami-induced changes using generalized
improvedfuzzyradialbasisfunctionneuralnetwork. Nat. Hazards2015,77,367–381. [CrossRef]
235. Peng,B.;Meng,Z.;Huang,Q.;Wang,C.PatchSimilarityConvolutionalNeuralNetworkforUrbanFlood
ExtentMappingUsingBi-TemporalSatelliteMultispectralImagery. RemoteSens. 2019,11,2492. [CrossRef]
236. Sakurada,K.;Tetsuka,D.;Okatani,T.Temporalcitymodelingusingstreetlevelimagery. Comput. Vis. Image
Underst. 2017,157,55–71. [CrossRef]
237. Wang,L.HeterogeneousDataandBigDataAnalytics. Autom. Control. Inf. Sci. 2017,3,8–15. [CrossRef]
RemoteSens.2020,12,1688 35of35
238. Bengio,Y.;Courville,A.C.;Vincent,P.UnsupervisedFeatureLearningandDeepLearning: AReviewand
NewPerspectives. arXiv2012,arXiv:1206.5538.
239. Guidotti,R.; Monreale,A.; Ruggieri,S.; Turini,F.; Giannotti,F.; Pedreschi,D.ASurveyofMethodsfor
ExplainingBlackBoxModels. ACMComput. Surv. 2019,51,1–42. [CrossRef]
240. Dietterich,T.G.StepsTowardRobustArtificialIntelligence. AIMag. 2017,38,3–24. [CrossRef]
241. Mueller,S.T.;Hoffman,R.R.;Clancey,W.;Emrey,A.;Klein,G.Explanationinhuman-AIsystems: Aliterature
meta-review, synopsis of key ideas and publications, and bibliography for explainable AI. arXiv 2019,
arXiv:1902.01876.
242. Shi,W.;Hao,M.Analysisofspatialdistributionpatternofchange-detectionerrorcausedbymisregistration.
Int. J.RemoteSens. 2013,34,6883–6897. [CrossRef]
243. Zhang,P.;Shi,W.;Wong,M.-S.;Chen,J.AReliability-BasedMulti-AlgorithmFusionTechniqueinDetecting
ChangesinLandCover. RemoteSens. 2013,5,1134–1151. [CrossRef]
244. Bruzzone,L.;Cossu,R.;Vernazza,G.Detectionofland-covertransitionsbycombiningmultidateclassifiers.
PatternRecognit. Lett. 2004,25,1491–1500. [CrossRef]
245. He,P.;Shi,W.;Miao,Z.;Zhang,H.;Cai,L.AdvancedMarkovrandomfieldmodelbasedonlocaluncertainty
forunsupervisedchangedetection. RemoteSens. Lett. 2015,6,667–676. [CrossRef]
246. Chen,L.-C.;Papandreou,G.;Kokkinos,I.;Murphy,K.;Yuille,A.L.DeepLab: SemanticImageSegmentation
withDeepConvolutionalNets,AtrousConvolution,andFullyConnectedCRFs. IEEETrans. PatternAnal.
Mach. Intell. 2018,40,834–848. [CrossRef][PubMed]
247. Wang,Z.;Acuna,D.;Ling,H.;Kar,A.;Fidler,S.Objectinstanceannotationwithdeepextremelevelset
evolution. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,LongBeach,
CA,USA,16–20June2019;pp.7500–7508.
©2020bytheauthors. LicenseeMDPI,Basel,Switzerland. Thisarticleisanopenaccess
articledistributedunderthetermsandconditionsoftheCreativeCommonsAttribution
(CCBY)license(http://creativecommons.org/licenses/by/4.0/).
